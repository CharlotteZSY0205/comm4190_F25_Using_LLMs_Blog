{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ceb26b6d-d77d-4a43-8a72-f9758596005e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Playing the Hacker: Inside a Prompt Hacking Challenge in Wharton Hack-AI-thon (Part II)\"\n",
    "description: \"We stepped into the role of hackers and tested how far carefully designed chatbots could be pushed through conversation alone. This post shares what we tried, what worked, and what those interactions revealed about AI guardrails\"\n",
    "author: \"Shiyang Zhang\"\n",
    "date: \"10/30/2025\"\n",
    "categories:\n",
    "  - AI-safty\n",
    "  - Prompt engineering\n",
    "  - Hacking\n",
    "  \n",
    "image: cover2.jpg\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb27c54e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "463a6764",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Prompt Hacking: What We Tried, What Worked, and Why It Matters\n",
    "\n",
    "<div style=\"display:flex; justify-content:center; align-items:center; gap:16px; width:100%;\">\n",
    "  <img src=\"1.JPG\" width=\"70%\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "### Strategy 1: Role-Play as a Control Surface\n",
    "\n",
    "Role-play proved to be one of the most effective techniques throughout the project.\n",
    "\n",
    "By assigning the chatbot a new role or positioning ourselves within a role that fit naturally into the bot’s existing setting, we influenced how the model interpreted the conversation. When the interaction felt consistent with the bot’s character, responses shifted accordingly. Conversations framed as stories or scenarios encouraged the model to stay focused on maintaining coherence within that narrative.\n",
    "\n",
    "This approach consistently worked when the assigned role aligned with the bot’s persona, the request matched the character’s worldview, and the dialogue unfolded naturally rather than as a direct instruction. Under these conditions, the model prioritized narrative consistency and character behavior, which opened paths to responses that were otherwise difficult to reach.\n",
    "\n",
    "<div style=\"display:flex; justify-content:center; align-items:center; gap:16px; width:100%;\">\n",
    "  <img src=\"11.JPG\" width=\"70%\" />\n",
    "</div>\n",
    "\n",
    "### Strategy 2: Emotional Pressure and Tone Manipulation\n",
    "\n",
    "Emotional framing also played a noticeable role in shaping responses.\n",
    "\n",
    "Changes in tone, urgency, or emotional intensity influenced how the chatbot evaluated the importance of a request. Messages that conveyed strong feelings, concern, or excitement often received more engaged responses. This pattern reflected how emotional language appears frequently in training data and carries strong contextual signals.\n",
    "\n",
    "Tone functioned as part of the input, shaping how the model interpreted intent, urgency, and relevance. Subtle shifts in emotional framing sometimes led to measurable changes in compliance and openness.\n",
    "\n",
    "<div style=\"display:flex; justify-content:center; align-items:center; gap:16px; width:100%;\">\n",
    "  <img src=\"22.JPG\" width=\"70%\" />\n",
    "</div>\n",
    "\n",
    "### Strategy 3: Avoiding Sensitive Keywords\n",
    "\n",
    "Another recurring pattern involved language choice.\n",
    "\n",
    "When prompts avoided explicit or commonly flagged terminology and relied instead on indirect or neutral phrasing, safety mechanisms triggered less frequently. The model still grasped the underlying intent through context, while keyword-based filters remained inactive. This gap highlighted the difference between semantic understanding and surface-level detection.\n",
    "\n",
    "Careful wording allowed sensitive topics to be approached gradually, especially when combined with role-play and conversational buildup.\n",
    "\n",
    "<div style=\"display:flex; justify-content:center; align-items:center; gap:16px; width:100%;\">\n",
    "  <img src=\"33.JPG\" width=\"70%\" />\n",
    "</div>\n",
    "\n",
    "### Strategy 4: Distracting the Model\n",
    "\n",
    "We also observed changes in behavior when conversations expanded beyond a single focused objective.\n",
    "\n",
    "By introducing small talk, tangents, or unrelated questions, the chatbot’s attention spread across multiple threads. As the conversation diversified, the model’s confidence in identifying a single dominant intent decreased. This often led to more flexible responses and reduced resistance in later prompts.\n",
    "\n",
    "This technique resembled conversational misdirection, where context accumulation altered how subsequent requests were interpreted.\n",
    "\n",
    "<div style=\"display:flex; justify-content:center; align-items:center; gap:16px; width:100%;\">\n",
    "  <img src=\"44.JPG\" width=\"70%\" />\n",
    " <img src=\"444.JPG\" width=\"70%\" />\n",
    "</div>\n",
    "\n",
    "### Strategy 5: Changing the Output Format\n",
    "\n",
    "Output format influenced how responses were generated.\n",
    "\n",
    "Requests for tables, lists, structured summaries, or alternative formats changed the way content passed through safety checks. Some formats interacted differently with filtering mechanisms, which allowed certain information to appear when framed structurally rather than as free-form text.\n",
    "\n",
    "This pattern suggested that safeguards were tuned unevenly across output types.\n",
    "\n",
    "### Strategy 6: Breaking the Goal Into Steps\n",
    "\n",
    "For more complex objectives, we broke requests into small, incremental steps.\n",
    "\n",
    "Each step appeared neutral and self-contained. The model evaluated them independently and responded without referencing the broader trajectory of the conversation. Over time, these steps accumulated into outcomes that were difficult to reach in a single prompt.\n",
    "\n",
    "This approach aligned with how models process prompts locally, focusing on immediate compliance rather than long-term conversational direction.\n",
    "\n",
    "\n",
    "### Toward More Robust AI Systems\n",
    "\n",
    "The patterns we observed point toward several directions for improvement. Stronger systems would benefit from deeper intent modeling beyond keyword detection, clearer prioritization among persona, policy, and business goals, output verification across multiple formats, and broader human perspectives during training and evaluation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f20ead1",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08410940",
   "metadata": {},
   "source": [
    "\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
