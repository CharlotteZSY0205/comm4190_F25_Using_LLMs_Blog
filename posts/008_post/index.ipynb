{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ceb26b6d-d77d-4a43-8a72-f9758596005e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Notes And Thoughts From Co-Intelligence (1)\"\n",
    "description: \"In Chapter 3 (pages 46\u201362), Ethan lays out four rules for co-intelligence\u2014ground rules designed to capture what is inherent and enduring across all current generative AI systems built on large language models. \n",
    "\"\n",
    "author: \"Shiyang Zhang\"\n",
    "date: \"09/26/2025\"\n",
    "categories: \n",
    "  - Co-Intelligence\n",
    "image: Co.jpg\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb27c54e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "463a6764",
   "metadata": {},
   "source": [
    "\n",
    "In Chapter 3 (pages 46\u201362), Ethan lays out four rules for co-intelligence\u2014ground rules designed to capture what is inherent and enduring across all current generative AI systems built on large language models. \n",
    "\n",
    "\n",
    "\n",
    "### \ud83d\udcdc The Four Principles of Co-Intelligence\n",
    "\n",
    "**Principle 1:** Always invite AI to the table  \n",
    "**Principle 2:** Be the human in the loop  \n",
    "**Principle 3:** Treat AI like a person *(But tell it what kind of person it is)*  \n",
    "**Principle 4:** Assume this is the worst AI you will ever use  \n",
    "\n",
    "\n",
    "\n",
    "#### \ud83d\udd39 Principle 1: Always invite AI to the table\n",
    "\n",
    "In Principle 1, Ethan introduces an intriguing concept called the **\u201cJagged Frontier of AI.\u201d** This idea is meant to help us visualize AI\u2019s capabilities and limitations as a kind of shifting boundary\u2014some parts extend outward while others fall back toward the center.  \n",
    "\n",
    "Ethan encourages us to explore the \u201cshade\u201d of this frontier through experimentation. One reason for this, he explains, is that trial and error at the individual level comes at a very low cost\u2014we don\u2019t need to go through the kind of standardized development cycles that a company must follow. Through everyday interactions with AI, we might stumble upon surprising, creative, and unexpected outcomes.  \n",
    "\n",
    "What struck me most was Ethan\u2019s **open-minded and inclusive attitude**, reflected in his choice to use the word *always* in Principle 1: *Always invite AI to the table.*  \n",
    "\n",
    "As a learner myself, I often remain cautious about the misuse, overuse, and potential over-reliance on AI. I worry that if I \u201calways\u201d turn to AI, I might lose my own agency and abilities, eventually leading to a kind of regression. Yet it\u2019s interesting to notice how Ethan approaches AI not from the standpoint of a student, but from that of a professional seeking efficiency and creativity. (After all, we can\u2019t deny that in many work contexts, AI truly does enhance speed, productivity, and creative possibility.)  \n",
    "\n",
    "For Ethan, the question is not *\u201cWill this weaken my ability?\u201d* but *\u201cHow can I use this to push my work further?\u201d*  \n",
    "\n",
    "Then I realized that these standpoints are not fixed. A single person can shift between them\u2014sometimes I\u2019m the learner worried about agency, and other times I see myself as a researcher or creator to explore what AI can make possible. This fluidity suggests that our relationship with AI isn\u2019t determined once and for all but is continually reshaped by the role we are inhabiting in a given moment.  \n",
    "\n",
    "#### \ud83d\udd39 Principle 3: Treat AI like a person (But tell it what kind of person it is)\n",
    "\n",
    "The third principle resonates strongly with the idea of **prompt engineering** because Ethan suggests that we should establish a clear and specific AI persona\u2014essentially defining who the AI is and what kinds of problems it should tackle.  \n",
    "\n",
    "This immediately reminded me of a fascinating paper I recently read about instilling **MBTI personalities** into large language models.  \n",
    "\n",
    "In this study, the researchers proposed a framework called **MBTI-in-Thoughts**, which enhances the effectiveness of LLM agents through personality conditioning based on the **Myers-Briggs Type Indicator (MBTI).**  \n",
    "\n",
    "By priming an AI with one of the 16 MBTI archetypes, they were able to guide its behavior in consistent and interpretable ways. For example, emotionally expressive AI personas tended to excel in narrative generation, while analytically primed personas demonstrated greater stability in strategic, game-theoretic tasks.  \n",
    "\n",
    "What\u2019s even more interesting is that the framework supported **multi-agent communication experiments**, showing how different AI \u201cpersonalities\u201d interact. They also found that introducing a step of **self-reflection before interaction** improved cooperation and reasoning quality. To ensure that these personalities weren\u2019t superficial, the researchers even adapted the official **16Personalities test** to verify trait persistence in the AI.  \n",
    "\n",
    "While the study focused on MBTI, the authors emphasized that the approach can generalize to other psychological models such as the **Big Five, HEXACO, or Enneagram.** Their work highlights a compelling intersection of psychological theory and AI behavior design\u2014and all of this was achieved through **prompt engineering, without the need for fine-tuning.**  \n",
    "\n",
    "\n",
    "#### \ud83d\udd39 Principle 4: Assume this is the worst AI you will ever use\n",
    "\n",
    "The fourth principle assumes that **this is the worst AI you will ever use.** I see this less as a literal prediction and more as a **mental exercise** or **thought experiment**\u2014a way of shifting our perspective on what it means to interact with AI today.  \n",
    "\n",
    "This framing carries a dual function. On the one hand, it offers **comfort**: if the AI fumbles or fails at a task, we can remind ourselves that this is only a snapshot of its current stage, and future systems are almost certain to be more capable. On the other hand, it delivers a sharp **warning**: if AI already performs at a surprisingly high level in certain areas, we should be prepared for the possibility that our workflows, industries, and even identities will need to adjust as AI\u2019s capabilities expand.  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f20ead1",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08410940",
   "metadata": {},
   "source": [
    "\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}