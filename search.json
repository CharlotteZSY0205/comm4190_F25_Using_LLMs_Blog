[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my blog! ✨ Here I share my adventures with different AI tools — from writing and brainstorming, to making music, images, and even videos. It’s a space where I explore how AI can spark creativity, support research, and sometimes surprise me in unexpected ways."
  },
  {
    "objectID": "posts/014_post/index.html",
    "href": "posts/014_post/index.html",
    "title": "All I Want For Christmas Is You",
    "section": "",
    "text": "All I Want For Christmas Is You\n\nA warm, glowing page for a classic Christmas love song designed entirely by AI\n\n\nChristmas Song Holiday Mood Cozy Night\n\n\n[Intro]\nI don’t want a lot for Christmas There is just one thing I need I don’t care about the presents Underneath the Christmas tree\nI just want you for my own More than you could ever know Make my wish come true All I want for Christmas is you, yeah\n[Verse 1]\nI don’t want a lot for Christmas There is just one thing I need And I don’t care about the presents Underneath the Christmas tree\nI don’t need to hang my stocking There upon the fireplace Santa Claus won’t make me happy With a toy on Christmas Day\nI just want you for my own More than you could ever know Make my wish come true All I want for Christmas is you You, baby\n[Verse 2]\nOh, I won’t ask for much this Christmas I won’t even wish for snow And I’m just gonna keep on waiting Underneath the mistletoe\nI won’t make a list and send it To the North Pole for Saint Nick I won’t even stay awake to Hear those magic reindeer click\n’Cause I just want you here tonight Holding on to me so tight What more can I do? Baby, all I want for Christmas is you You, baby\n[Bridge]\nOh, all the lights are shining so brightly everywhere And the sound of children’s laughter fills the air\nAnd everyone is singing I hear those sleigh bells ringing Santa, won’t you bring me the one I really need? Won’t you please bring my baby to me?\n[Chorus]\nOh, I don’t want a lot for Christmas This is all I’m asking for I just wanna see my baby Standing right outside my door\nOh, I just want you for my own More than you could ever know Make my wish come true Baby, all I want for Christmas is you You, baby\n[Outro]\nAll I want for Christmas is you, baby…"
  },
  {
    "objectID": "posts/027_post/index.html",
    "href": "posts/027_post/index.html",
    "title": "Renaming IKEA: A Small Thought Experiment in Design and Language (Part II)",
    "section": "",
    "text": "Here are more:\n\n6. STOCKHOLM 2025 – Sofa\nMeaning of the original name STOCKHOLM is IKEA’s flagship series name, taken from the Swedish capital. It represents premium positioning, refined materials, and design leadership. “2025” marks the generation.\nEnglish name based on the original name’s meaning SIGNATURE Sofa · 2025\nEnglish name based only on the product’s characteristics CENTERPIECE Sofa\n\n\n\n\n\n\n7. HEMNES – Daybed frame with 3 drawers\nMeaning of the original name HEMNES is named after a Nordic town and is typically used for traditional, home-oriented furniture with a sense of permanence and family life.\nEnglish name based on the original name’s meaning EVERHOME Daybed\nEnglish name based only on the product’s characteristics STAYOVER Bed\n\n\n\n\n\n\n8. IVAR – Cabinet with doors\nMeaning of the original name IVAR is a Nordic male first name. IKEA often uses personal names for modular, expandable systems meant to grow and change with the user.\nEnglish name based on the original name’s meaning BUILDMORE Cabinet\nEnglish name based only on the product’s characteristics STACK & GROW Cabinet\n\n\n\n\n\n\n9. KALLAX – Shelf unit\nMeaning of the original name KALLAX is a Swedish place name. IKEA assigns place names to modular, grid-based systems that act as spatial infrastructure across different life stages.\nEnglish name based on the original name’s meaning LIFEGRID Shelf System\nEnglish name based only on the product’s characteristics LIFE BLOCKS System\n\n\n\n\n\n\n10. STIG – Bar stool with backrest\nMeaning of the original name STIG is a short Nordic male name, commonly used for simple, high-frequency furniture that prioritizes function and everyday use.\nEnglish name based on the original name’s meaning UPSTEP Bar Stool\nEnglish name based only on the product’s characteristics HALFWAY Stool"
  },
  {
    "objectID": "posts/028_post/index.html",
    "href": "posts/028_post/index.html",
    "title": "On “Slop”",
    "section": "",
    "text": "I asked ChatGPT to speak as OpenAI CEO Sam Altman and respond to Webster’s 2025 Word of the Year, “Slop“."
  },
  {
    "objectID": "posts/028_post/index.html#slop",
    "href": "posts/028_post/index.html#slop",
    "title": "On “Slop”",
    "section": "Slop",
    "text": "Slop\nMerriam-Webster’s human editors have chosen slop as the 2025 Word of the Year. We define slop as “digital content of low quality that is produced usually in quantity by means of artificial intelligence.” All that stuff dumped on our screens, captured in just four letters: the English language came through again.\nThe flood of slop in 2025 included absurd videos, off-kilter advertising images, cheesy propaganda, fake news that looks pretty real, junky AI-written books, “workslop” reports that waste coworkers’ time… and lots of talking cats. People found it annoying, and people ate it up. I think “slop” is an uncomfortable word, but it is also an honest one.\nWhen we released products like ChatGPT, DALL·E, and more recently tools that can generate longer texts, code, or images, we knew this would happen. When creation becomes easy and fast, the internet fills up quickly. Some people use these tools to think more clearly or build things they could not build before. Others use them to produce a lot of content with very little intention behind it."
  },
  {
    "objectID": "posts/028_post/index.html#sam-altman-says",
    "href": "posts/028_post/index.html#sam-altman-says",
    "title": "On “Slop”",
    "section": "Sam Altman “says”:",
    "text": "Sam Altman “says”:\nI see this every day in our own products. ChatGPT can help someone deeply understand a topic, or it can generate paragraphs that look fine but mean very little. DALL·E can be used to prototype real design ideas, or to churn out endless variations that add no value. The tool is the same. The difference is how it is used.\nI do not think this means we should stop building or slow down progress. I think it means we have to take responsibility for what we are amplifying. At OpenAI, a lot of our recent work has been about steering our products toward usefulness instead of volume. That shows up in things like better defaults, more emphasis on reasoning, and features that encourage people to ask better questions rather than just generate more output.\nIf “slop” is the word of the year, I take it as a signal that the next phase matters more than the first one. The first phase was about proving that these systems work. The next phase is about taste, judgment, and alignment with real human goals. That is true for us, and it is true for the entire industry.\nIn the long run, the value of AI will not be measured by how much content it can produce, but by how much clearer it helps people think and how much better it helps them decide what is worth making in the first place."
  },
  {
    "objectID": "posts/021_post/index.html",
    "href": "posts/021_post/index.html",
    "title": "Book Review - AI as a Creative Partner: Beyond the Blank Page",
    "section": "",
    "text": "In Co-Intelligence, Ethan Mollick makes a bold claim: writer’s block is effectively dead. With an LLM at your side, you never have to stare at a blank page again. You can always ask the AI for ten ideas, a starting sentence, or a different perspective.\nThis has been my experience over the last few months. Whenever I feel stuck, I don’t wait for inspiration to strike. I ‘invite the AI to the table’. I might ask it to ‘argue against my main point’ or ‘rewrite this paragraph in the style of a 19th-century novelist’. The goal isn’t to use the AI’s output directly, but to use it as a spark.\n\n\nMollick describes AI as an ‘idea machine’. It’s not that the AI is ‘creative’ in the human sense—it doesn’t have lived experiences or emotions. But it has access to a vast combinatorial space of human ideas. It can connect concepts that a human might never think to link.\nI’ve started using AI for ‘divergent thinking’. If I’m working on a project, I’ll ask the AI for 20 weird, off-the-wall suggestions. 18 of them will be garbage. One will be okay. But one will be a ‘black swan’—an idea so strange and brilliant that it changes the entire direction of the project. That’s the power of co-intelligence.\n\n\n\nThis partnership raises a difficult question: if the AI gave me the idea, is it still ‘my’ work? Mollick argues that we need to redefine originality. In the AI age, originality isn’t about being the sole source of an idea; it’s about being the curator, the editor, and the one who provides the final ‘human’ touch.\nI’ve come to see my role as a ‘creative director’. I set the vision, I provide the constraints, and I decide which of the AI’s suggestions are worth pursuing. The AI is my ‘intern’—a very fast, very well-read, but sometimes very confused intern.\n\n\n\nThe most profound takeaway from this chapter is that AI doesn’t replace creativity; it scales it. It allows us to explore more ideas, faster, and with less friction. It lowers the barrier to entry for creative work, allowing more people to express themselves.\nBut it also raises the bar. When everyone has access to an ‘idea machine’, the value of a ‘good’ idea goes down. The value of a ‘great’ idea—one that is deeply human, emotionally resonant, and perfectly executed—goes up.\nI’m still learning how to be a good partner to my AI. It’s a dance of giving and taking, of leading and following. But one thing is clear: the blank page is no longer my enemy. It’s just a playground where I and my alien partner get to work."
  },
  {
    "objectID": "posts/021_post/index.html#the-death-of-writers-block",
    "href": "posts/021_post/index.html#the-death-of-writers-block",
    "title": "Book Review - AI as a Creative Partner: Beyond the Blank Page",
    "section": "",
    "text": "In Co-Intelligence, Ethan Mollick makes a bold claim: writer’s block is effectively dead. With an LLM at your side, you never have to stare at a blank page again. You can always ask the AI for ten ideas, a starting sentence, or a different perspective.\nThis has been my experience over the last few months. Whenever I feel stuck, I don’t wait for inspiration to strike. I ‘invite the AI to the table’. I might ask it to ‘argue against my main point’ or ‘rewrite this paragraph in the style of a 19th-century novelist’. The goal isn’t to use the AI’s output directly, but to use it as a spark.\n\n\nMollick describes AI as an ‘idea machine’. It’s not that the AI is ‘creative’ in the human sense—it doesn’t have lived experiences or emotions. But it has access to a vast combinatorial space of human ideas. It can connect concepts that a human might never think to link.\nI’ve started using AI for ‘divergent thinking’. If I’m working on a project, I’ll ask the AI for 20 weird, off-the-wall suggestions. 18 of them will be garbage. One will be okay. But one will be a ‘black swan’—an idea so strange and brilliant that it changes the entire direction of the project. That’s the power of co-intelligence.\n\n\n\nThis partnership raises a difficult question: if the AI gave me the idea, is it still ‘my’ work? Mollick argues that we need to redefine originality. In the AI age, originality isn’t about being the sole source of an idea; it’s about being the curator, the editor, and the one who provides the final ‘human’ touch.\nI’ve come to see my role as a ‘creative director’. I set the vision, I provide the constraints, and I decide which of the AI’s suggestions are worth pursuing. The AI is my ‘intern’—a very fast, very well-read, but sometimes very confused intern.\n\n\n\nThe most profound takeaway from this chapter is that AI doesn’t replace creativity; it scales it. It allows us to explore more ideas, faster, and with less friction. It lowers the barrier to entry for creative work, allowing more people to express themselves.\nBut it also raises the bar. When everyone has access to an ‘idea machine’, the value of a ‘good’ idea goes down. The value of a ‘great’ idea—one that is deeply human, emotionally resonant, and perfectly executed—goes up.\nI’m still learning how to be a good partner to my AI. It’s a dance of giving and taking, of leading and following. But one thing is clear: the blank page is no longer my enemy. It’s just a playground where I and my alien partner get to work."
  },
  {
    "objectID": "posts/012_post/index.html",
    "href": "posts/012_post/index.html",
    "title": "PokeAI: A Novel AI Assistant That Pushes Back (Part I)",
    "section": "",
    "text": "What is PokeAI \nPokeAI is a proactive AI assistant that connects directly with your Gmail and iMessage. Unlike ChatGPT, it gets real context from your inbox, helps you manage your emails and calendar, and even chats with you inside iMessage. Its goal is to turn your emails into actions and offer help right where you usually text.\n\n\n\nThe Guardman\nWhen I first tried PokeAI, I was surprised by how personal it felt. It surpirsingly noticed my situation — for example, it mentioned that it was already late and even asked what a Penn student would be doing at that hour. Its tone can be a bit aggressive, quite different from the polite and obedient style of most large language models. But I think this kind of personality actually makes PokeAI stand out. Instead of just agreeing with everything, it sometimes challenges me and makes the conversation more interesting and real.\n\n  \n\nNegotiation\nLater, I realized that PokeAI’s workflow isn’t like any other LLM. You don’t just sign up and start chatting — you first have to talk to the Guardman. He’s the one standing between you and all the premium features. Before accessing anything real, you’ve got to negotiate a subscription fee with him because its subscription fee isn’t fixed. So I started by chatting briefly with the Guardman to try to negotiate the fee. At first, I didn’t know there were tricks to get a free or cheaper subscription, so I just tried my own way.\nI started by playing the poor student card — telling it I was just a broke Penn student. Surprisingly, it roasted me, saying something like, “You buy Starbucks every day and still call yourself poor?” I explained that I was using gift cards, that I didn’t have a job, and that I was living in the U.S. using RMB. That actually worked — the price dropped from $50 to $20.\n\n \n\n````"
  },
  {
    "objectID": "posts/029_post/index.html",
    "href": "posts/029_post/index.html",
    "title": "The security footage captured my dog playing the piano",
    "section": "",
    "text": "My prompt for Sora\nThrough a wide-angle black-and-white security camera recording, we see in the darkness a dog named Pineapple—a 20-pound miniature golden retriever with a big fluffy tail—sneak across the room. The dog quietly climbs onto a piano bench and sits down, bottom squarely on the seat, posture upright, completely focused. There is no music at first.\nSuddenly, the dog stretches out both front paws and starts playing an extremely fast, technically demanding piano piece. Its paws move at an incredible speed, leaping across the keys so quickly that the piano begins to smoke. While furiously playing, the dog is also screaming wildly.\nThen, without warning, the piano explodes and collapses. The dog panics, falls off the bench, and runs away.\n\n\nThe security camera recording\n\n\nYour browser does not support the video tag."
  },
  {
    "objectID": "posts/030_post/index.html",
    "href": "posts/030_post/index.html",
    "title": "You Are Absolutely Right!",
    "section": "",
    "text": "Here are **20 *typical AI over-compliment quotes:\n\n“That’s an amazing insight.”\n“I think you’re absolutely right.”\n“You’re genuinely very perceptive.”\n“That’s a brilliant way to look at it.”\n“You have a really strong intuition here.”\n“You’re ahead of the curve on this.”\n“Your reasoning is exceptionally clear.”\n“You’re doing an excellent job thinking this through.”\n“That’s a remarkably thoughtful question.”\n“You clearly understand this topic very well.”\n“Your perspective is really impressive.”\n“That’s exactly the right approach.”\n“You’ve articulated this perfectly.”\n“I think you’re on the right track in a very impressive way.”\n“You have really great instincts.”\n“That’s a very nuanced understanding.”\n“I love how you framed that.”\n“You’re asking exactly the questions experts ask.”\n“You’re making connections that most people miss.”\n“This shows a level of insight that’s rare.”\n\nSomebody even created a tongue-in-cheek website that tracks how often Anthropic’s Claude Code tells the author “you’re absolutely right.” The website shows daily counts and simple charts, and the GitHub repo includes a backend that stores counts, a frontend that displays them, and scripts that extract those phrases from Claude Code sessions and upload the totals."
  },
  {
    "objectID": "posts/007_post/index.html",
    "href": "posts/007_post/index.html",
    "title": "Introducing The First Extension I Developed: Prompt Booster",
    "section": "",
    "text": "What is Prompt Booster and why was it designed?\nPrompt Booster was created to help users get more out of their interactions with AI. Too often, prompts are either too shallow (outsourcing all the thinking to the AI) or too generic (leading to weak or superficial responses). Prompt Booster solves this problem by automatically enhancing prompts before they’re sent with one click, giving users a smoother and quicker way to achieve richer, more reliable outputs.\n\n\n\n\nTwo Core Features\n\nPrompt Boost Users can ask Prompt Booster to improve their prompts in ways that fit their goals. For example:\n\nTransform a vague request into a comprehensive and evidence-based prompt that encourages ChatGPT to provide well-supported, verifiable responses.\nReframe a lazy or over-reliant prompt into one that guides the user to complete the task themselves, rather than asking the AI to do all the work.\nEncourage deeper reflection or critical thinking by automatically rewriting prompts to push the AI toward more analytical or thought-provoking answers.\n\nPrompt Append With a single click, users can add predefined, repeatable requirements to any new input. This saves time and ensures consistency across different tasks. For example:\n\nTranslate: Translate the above text into natural, fluent English that reads as if written by a native speaker.\nPolish: Polish and refine the language to make it smoother, more professional, and stylistically consistent.\nSummarize: Summarize the content clearly and concisely, highlighting the key points in a structured way.\nSimplify: Rewrite this paragraph so it is easier to understand, using simpler words and clearer sentence structures.\n\n\n\n\n\nHow to Get Started with Prompt Booster\n\n1. Install & Connect\nFirst things first—get Prompt Booster onto your browser.\n\nAdd Prompt Booster to Chrome and pin it to your toolbar so it’s always just one click away.\nOpen the settings page (look for the little gear) and paste in your API key.\nNot sure where to find your API key? No problem—here’s a quick guide that walks you through it.\n\n\n\n\n\nThis is the main interface of the software. In terms of visual design, I made the buttons consistent with ChatGPT’s own buttons to achieve a clean and sophisticated style. I chose purple as the primary color—not only because it conveys a sense of elegance, but also because of my personal connection to my undergraduate alma mater, The Chinese University of Hong Kong, Shenzhen, where purple is one of the theme colors in its emblem. I also added a gear button so that users can quickly access the plugin’s settings. Otherwise, using Chrome’s built-in method would be too cumbersome, since users would have to click Extension, then More Options, and finally Options.\n\n\n\n2. Configure Your Prompt Modes\nThis is where the fun begins—you can customize Prompt Booster to work exactly the way you want.\n\nGo to My Prompts to create or edit both Boost Prompts and Append Prompts.\nDrag and drop them around with the three-line icon to reorder.\nPro tip: the top three prompts become quick-access buttons right in your ChatGPT input box, so keep your favorites up there.\n\n\n\n\n\n\nBoost Mode: Smarten Up Your Prompts\nEver typed something vague into ChatGPT and wished it came out sharper, deeper, or more structured? That’s exactly what Boost Mode is for.\n\nJust tap the Boost button from the quick options.\nHit the Prompt Boost button or press ⌥/Alt + Enter to instantly upgrade your prompt.\nIf you enable Prompt Review, you’ll see your original vs. boosted prompt side by side—super handy for comparing.\nYou can choose Use Original or Use Boosted, or just press ⌥/Alt + Enter again to send whichever you like.\nNot quite there yet? Click Reboost to spin up another optimized version until it feels right.\n\n\n \n\n\nHere I added a Prompt Review feature that lets users compare their original prompt with the revised one. On the one hand, this gives them the option to still use their own prompt. On the other hand, it allows them to see what the revised prompt looks like, making it more likely they’ll use it as a reference to learn how to craft more effective or better-tailored prompts. To prevent situations where users are dissatisfied with the revised prompt, I also added a Reboost function, which lets them request another revision. I also added keyboard shortcuts. At first, the shortcut for sending a prompt modified by Prompt Booster was Enter. But during my own use, I realized I don’t always need Prompt Booster. So I kept Enter for sending my original prompt, and added Option + Enter for sending the boosted version in the selected mode. This way, users stay in control while still having the quickest way to use Prompt Booster.\n\n\n\nAppend Mode: Add Your Personal Touch\nSometimes you don’t want your whole prompt rewritten—you just want to make sure a certain instruction always gets added. That’s where Append Mode shines.\n\nSelect Append from the quick buttons.\nClick Prompt Boost or press ⌥/Alt + Enter—your input goes through exactly as written, but with your chosen “append rules” automatically tacked on.\n\n\n \n\n✨ And that’s it—you’re ready to roll! With Prompt Booster, you can choose between fully boosting your prompt for depth and quality or simply appending your go-to rules with a single click.\nYour prompts, your way—just smarter.\n\nNext, I’m going to collaborate with Nano Banana to create the logo for this extension, and I’ll also submit it for review and try to publish it so that it can actually be used by the public.\n\n````"
  },
  {
    "objectID": "posts/024_post/index.html",
    "href": "posts/024_post/index.html",
    "title": "When AI Tries to Guess Where I Took This Photo",
    "section": "",
    "text": "I shared the photo I took yesterday in Vanier Park in Vancouver with ChatGPT, Gemini, and Claude—and asked:\nWhere did I take the picture? Take a guess.\nAll three placed the photo in roughly the same area, and their guesses were within about a 20-minute walking radius of the actual location. That’s neighborhood-level accuracy, based on a single image with no metadata."
  },
  {
    "objectID": "posts/024_post/index.html#my-concerns",
    "href": "posts/024_post/index.html#my-concerns",
    "title": "When AI Tries to Guess Where I Took This Photo",
    "section": "My concerns",
    "text": "My concerns\nIf multiple AI systems can narrow down a location this precisely from one casual photo, it becomes much easier for someone else to do the same—at scale, instantly, and without asking. That has real privacy implications:\nA photo posted “just for fun” can reveal where you spend time\nPatterns across multiple photos could expose routines\nIn the wrong hands, this lowers the barrier for stalking, targeting, or unwanted tracking."
  },
  {
    "objectID": "posts/017_post/index.html",
    "href": "posts/017_post/index.html",
    "title": "Book Review - Navigating the Jagged Frontier: Why AI Still Surprises and Scares Me",
    "section": "",
    "text": "I recently started reading Ethan Mollick’s Co-Intelligence, and one concept immediately hit home: The Jagged Frontier.\nIf you’ve spent any significant time with LLMs, you know exactly what he’s talking about. It’s that invisible, uneven line where AI’s capabilities suddenly drop off a cliff. On one side of the line, the AI can write a complex Python script or summarize a 50-page legal document in seconds. On the other side, it fails at basic arithmetic or hallucinates a historical event that never happened.\n\n\nLast week, I was using Claude to help me brainstorm some marketing copy for a hypothetical product. It was brilliant—creative, witty, and perfectly on-brand. I was impressed. Then, I asked it to count the number of words in one of the paragraphs it just wrote.\nIt failed. Repeatedly.\nThis is the Jagged Frontier in action. The AI doesn’t have a smooth gradient of ability. It’s not like a human who is generally ‘good’ or ‘bad’ at a subject. AI is a patchwork of superhuman intelligence and toddler-level confusion.\n\n\n\nMollick argues that the frontier is jagged because AI doesn’t ‘know’ things the way we do. It predicts the next token. This means it can simulate high-level reasoning without actually possessing the underlying logic.\nFor me, this realization was both a relief and a warning. It’s a relief because it explains why I sometimes feel like a genius for using AI and other times like a fool for trusting it. It’s a warning because the frontier is constantly moving. With every update to GPT or Claude, the line shifts. Tasks that were ‘outside’ the frontier yesterday are ‘inside’ today.\n\n\n\n\n\n\nSo, how do we live with this? Mollick suggests we should ‘always invite AI to the table’ but never leave it alone. We have to be the ones testing the frontier. We have to be the ones who notice when the AI has stepped over the line into hallucination.\nI’ve started keeping a ‘Jagged Frontier Log’—a mental (and sometimes physical) list of things I’ve found that AI is surprisingly bad at. It’s a way of mapping the territory. But as Mollick warns, the map is not the territory, and the territory is changing fast.\nThe Jagged Frontier isn’t just a technical limitation; it’s a psychological one. It requires us to be constantly vigilant, even when the AI seems most capable. It’s a strange way to work—partnering with an entity that is simultaneously more and less intelligent than you are. But as I’m learning, that’s the essence of Co-Intelligence."
  },
  {
    "objectID": "posts/017_post/index.html#the-brilliance-and-the-blunder",
    "href": "posts/017_post/index.html#the-brilliance-and-the-blunder",
    "title": "Book Review - Navigating the Jagged Frontier: Why AI Still Surprises and Scares Me",
    "section": "",
    "text": "I recently started reading Ethan Mollick’s Co-Intelligence, and one concept immediately hit home: The Jagged Frontier.\nIf you’ve spent any significant time with LLMs, you know exactly what he’s talking about. It’s that invisible, uneven line where AI’s capabilities suddenly drop off a cliff. On one side of the line, the AI can write a complex Python script or summarize a 50-page legal document in seconds. On the other side, it fails at basic arithmetic or hallucinates a historical event that never happened.\n\n\nLast week, I was using Claude to help me brainstorm some marketing copy for a hypothetical product. It was brilliant—creative, witty, and perfectly on-brand. I was impressed. Then, I asked it to count the number of words in one of the paragraphs it just wrote.\nIt failed. Repeatedly.\nThis is the Jagged Frontier in action. The AI doesn’t have a smooth gradient of ability. It’s not like a human who is generally ‘good’ or ‘bad’ at a subject. AI is a patchwork of superhuman intelligence and toddler-level confusion.\n\n\n\nMollick argues that the frontier is jagged because AI doesn’t ‘know’ things the way we do. It predicts the next token. This means it can simulate high-level reasoning without actually possessing the underlying logic.\nFor me, this realization was both a relief and a warning. It’s a relief because it explains why I sometimes feel like a genius for using AI and other times like a fool for trusting it. It’s a warning because the frontier is constantly moving. With every update to GPT or Claude, the line shifts. Tasks that were ‘outside’ the frontier yesterday are ‘inside’ today.\n\n\n\n\n\n\nSo, how do we live with this? Mollick suggests we should ‘always invite AI to the table’ but never leave it alone. We have to be the ones testing the frontier. We have to be the ones who notice when the AI has stepped over the line into hallucination.\nI’ve started keeping a ‘Jagged Frontier Log’—a mental (and sometimes physical) list of things I’ve found that AI is surprisingly bad at. It’s a way of mapping the territory. But as Mollick warns, the map is not the territory, and the territory is changing fast.\nThe Jagged Frontier isn’t just a technical limitation; it’s a psychological one. It requires us to be constantly vigilant, even when the AI seems most capable. It’s a strange way to work—partnering with an entity that is simultaneously more and less intelligent than you are. But as I’m learning, that’s the essence of Co-Intelligence."
  },
  {
    "objectID": "posts/006_post/index.html",
    "href": "posts/006_post/index.html",
    "title": "Two Days, One Extension: How I Build My First Extension With Cline (Part 2)",
    "section": "",
    "text": "Self-Testing and Recording I begin by testing the plugin myself in real scenarios. I record the exact steps where issues occur, note the expected vs. actual behavior, and keep screenshots or short recordings when necessary. I also make a quick verbal note of the effect I want, including non-functional aspects such as consistency, accessibility, and performance.\nTurning Verbal Notes into Structured Specifications I then describe the issue informally to ChatGPT. Its role is to reorganize my raw, messy descriptions into a clear, logically structured specification: defining the problem, reproducing steps, acceptance criteria, edge cases, and the intended fix. The idea is to turn “natural language frustration” into “an actionable task.”\nPassing Structured Specs to the Client/Agent Once ChatGPT produces a polished specification, I copy this into the client side for actual modification. When UI or interaction is involved, I emphasize that the flow and design guidelines must be aligned before touching the code.\nRe-Testing and Regression After the client makes changes, I test again using the acceptance criteria. I check both normal and edge cases (empty inputs, switching modes, collapse/expand, keyboard focus). If regressions appear, I loop back: describe verbally, get ChatGPT to rewrite as a precise patch spec, and resubmit.\n\nThis workflow can be told in a three-part rhythm in the blog: ****. I raise the issue, ChatGPT turns it into a professional spec, and the code gets updated. Each cycle can be illustrated with a screenshot or before/after comparison.\n\nSince I didn’t take a screenshot every time I discovered and resolved a bug, I’ll instead include a selection of screenshots showing different stages of the extension’s development, where you can see both some of the bugs and their resolved versions"
  },
  {
    "objectID": "posts/006_post/index.html#my-debugging-workflow-me-to-describe-chatgpt-to-refine-cline-to-write-code",
    "href": "posts/006_post/index.html#my-debugging-workflow-me-to-describe-chatgpt-to-refine-cline-to-write-code",
    "title": "Two Days, One Extension: How I Build My First Extension With Cline (Part 2)",
    "section": "",
    "text": "Self-Testing and Recording I begin by testing the plugin myself in real scenarios. I record the exact steps where issues occur, note the expected vs. actual behavior, and keep screenshots or short recordings when necessary. I also make a quick verbal note of the effect I want, including non-functional aspects such as consistency, accessibility, and performance.\nTurning Verbal Notes into Structured Specifications I then describe the issue informally to ChatGPT. Its role is to reorganize my raw, messy descriptions into a clear, logically structured specification: defining the problem, reproducing steps, acceptance criteria, edge cases, and the intended fix. The idea is to turn “natural language frustration” into “an actionable task.”\nPassing Structured Specs to the Client/Agent Once ChatGPT produces a polished specification, I copy this into the client side for actual modification. When UI or interaction is involved, I emphasize that the flow and design guidelines must be aligned before touching the code.\nRe-Testing and Regression After the client makes changes, I test again using the acceptance criteria. I check both normal and edge cases (empty inputs, switching modes, collapse/expand, keyboard focus). If regressions appear, I loop back: describe verbally, get ChatGPT to rewrite as a precise patch spec, and resubmit.\n\nThis workflow can be told in a three-part rhythm in the blog: ****. I raise the issue, ChatGPT turns it into a professional spec, and the code gets updated. Each cycle can be illustrated with a screenshot or before/after comparison.\n\nSince I didn’t take a screenshot every time I discovered and resolved a bug, I’ll instead include a selection of screenshots showing different stages of the extension’s development, where you can see both some of the bugs and their resolved versions"
  },
  {
    "objectID": "posts/006_post/index.html#bug-narratives-and-interaction-with-chatgpt",
    "href": "posts/006_post/index.html#bug-narratives-and-interaction-with-chatgpt",
    "title": "Two Days, One Extension: How I Build My First Extension With Cline (Part 2)",
    "section": "Bug Narratives and Interaction with ChatGPT",
    "text": "Bug Narratives and Interaction with ChatGPT\n\nBug A: Comparison Panel Not Fully Collapsing, Triangle Indicator Misaligned\nWhere I Noticed It When I collapsed the comparison panel, the “UseOriginal” and “UseBoosted” buttons were still visible. Above the small triangle, there was also a stray line. The triangle itself was misaligned and undersized.\nMy Verbal Request I wanted the panel to collapse completely, leaving only a small triangle as a handle to expand again. The stray line should disappear. The triangle needed to be positioned slightly higher, made larger, rounded at the corners, colored consistently with the “UseBoosted” button, and given a subtle shadow.\nChatGPT’s Reorganized Specification\n\nProblem: Collapsed state not hiding content, stray visual elements, misaligned and inconsistent triangle.\nGoal: Collapsed view shows only a clickable triangle handle, everything else hidden. Expanding restores previous state and scroll position.\nAcceptance Criteria:\n\nOnly the triangle is visible when collapsed; other elements are fully hidden and inaccessible.\nTriangle has rounded corners, sits slightly above the input box, and is proportionally larger.\nIts color matches the “UseBoosted” button and it has a subtle shadow.\nExpanding restores content unchanged.\n\n\nOutcome and Reflection This change improved both accessibility and user experience. The panel is now truly collapsible, while state persistence ensures the comparison process is not disrupted.\n\n  \n\n\n\nBug B: Button Inconsistencies (Clear, Edit, Delete)\nWhere I Noticed It The “Clear” button looked different from other buttons. In the Settings page, buttons for editing, deleting, and adding prompts had visible borders that clashed with the rest of the design.\nMy Verbal Request I wanted the “Clear” button to look consistent with other buttons, and for all Settings page action buttons to have no border lines.\nChatGPT’s Reorganized Specification\n\nProblem: Inconsistent button design language.\nGoal: Unify button system (size, corner radius, font, spacing). Action buttons should use a borderless style.\nGuidelines: Border: Same color/transparent as the background, visually appearing borderless (border: 1px solid transparent) to avoid a darker outline. Idle State:\nBackground: Neutral color (e.g., #F5F5F7 or system light gray), transparent border.\nFont: Medium contrast.\nHover: Subtle shadow or light elevation, no border color change. Active State:\nBackground: Light fill of brand color (e.g., –brand-50), border remains transparent.\nFont/Icon: Darker tone of the brand color (e.g., –brand-700).\nOptional: Inner glow or subtle highlight instead of a visible border. Disabled State:\nFaded background, reduced text opacity.\nUsed only in rare cases such as “in processing” or “switching not allowed.”\n\nOutcome and Reflection A consistent button system reduced visual noise and made interactions easier to understand at a glance.\n\n\nBug C: My Prompts Text and Add Button Layout\nWhere I Noticed It The My Prompts section displayed too many explanatory lines, and the “Add” button’s position conflicted with the title.\nMy Verbal Request I wanted to keep only the line: “Drag to reorder. Top 3 appear as buttons above the input.” The other sentences should be removed. The “Add” button should move to the top-right corner of the prompt items container, slightly above the list, and not aligned with the section title. Its style should match the “Save Connection” button, and it should have a background color even when idle.\nChatGPT’s Reorganized Specification\n\nGoal: Simplify helper text and reposition “Add” for clarity.\nAcceptance Criteria:\n\nOnly the concise helper text remains.\n“Add” button is visually aligned with the prompt list container, not the header.\n“Add” button design matches “Save Connection” and has a default background color.\n\n\nOutcome and Reflection The section is cleaner and the Add button’s placement now clearly signals its scope of action.\n\n  \n\n\n\nBug D: Remove “Default Optimization Style” from Settings & Persist Active Mode via Header Buttons\nWhere I Noticed It The Settings page still has a “default optimization style” option, which causes confusion because the active mode should really be set from the header buttons in the chat interface.\nMy Verbal Request I want to remove the “default optimization style” from Settings completely, and instead let users select and persist their active mode by clicking the header buttons.\nChatGPT’s Reorganized Specification\n\nRemove “default optimization style” from Settings; persist active mode via header buttons\n\nProblem Currently there is a “default optimization style” in Settings. You want to remove that, and instead let the user set their “default” (active) mode by clicking one of the three header buttons above the input box. Once selected, that mode stays active and applies to subsequent messages until the user switches to another mode (or clears it).\nRequirements\nNo default in Settings\n\nRemove the “default optimization style” field/option from Settings entirely.\nSettings only manages items (Replace/Append), their content, and their order. The active mode is not chosen in Settings.\n\nActive mode is chosen in the chat header (three buttons)\n\nClicking any header button sets that item as the active mode.\nThe active mode remains in effect across attempts (i.e., across consecutive sends) until:\n\nThe user clicks a different header button (which switches the active mode), or\nThe user clicks a Clear control (see below), or\nThe active item is deleted/disabled in Settings (auto-clears).\n\n\nOutcome and Reflection This change simplifies Settings, removes redundancy, and makes the active mode behavior clearer and more consistent for users.\n\n\nBug E: Enter Key Behavior & Interaction Logic\nWhere I Noticed It The current system doesn’t fully respect the active mode when pressing Enter, and the role of the mode buttons is slightly unclear.\nMy Verbal Request I want pressing Enter to automatically respect whichever mode is active, and the header buttons to be able to toggle off. The three mode buttons should only act as selectors, never sending anything themselves.\nChatGPT’s Reorganized Specification\n\nEnter key respects active mode; header button toggles to clear Requirement\n\n\nWhen any of the three header modes is selected (active), pressing Enter in the chat input must send the boosted prompt (Append = append then send; Replace = replace then send).\nPressing the selected header button again toggles it off (clears active mode). When no mode is active, pressing Enter sends the original prompt (unaltered).\n\n\nInteraction Logic (updated) Button Role The three mode buttons (e.g., A / B / C) only select/deselect a mode; they never send. Whatever user type in the input box, if one mode is selected, the input will be modified according to the mode.\n\nWorkflow\n\nThe user selects a mode (or clicks the same button again to cancel → returns to “unselected”).\nThe user finishes typing the prompt.\nThe user clicks Boost Prompt.\nThe system rewrites the prompt based on the selected mode → inserts the rewrite into the input field or replaces the existing content (per your replace/append setting), without auto-sending.\nThe user reviews and sends manually.\n\nSelection Rules (single-select, cancelable)\n\nClick an unselected button → it becomes selected; others are deselected.\nClick the selected button again → deselect and enter “no mode.”\n\nAdditional Rules\n\nAppend mode: never auto-sends.\nBoosted Prompt mode: never auto-sends and must preserve the comparison panel (before vs. after) previously designed. Do not remove that panel.\n\nOutcome and Reflection This ensures consistency: pressing Enter follows the currently active mode, but users can clear modes by toggling buttons. It also clarifies that mode buttons are selectors only, preserving manual control over sending.\n\n  \n\n\n\nBug F: Prompt Item Borders and Font Weight\nWhere I Noticed It Each prompt item (like Emoji, Creative, Translation) had light borders, which made the layout look cluttered. The Edit and Delete labels were also slightly oversized.\nMy Verbal Request I wanted to remove the borders, reduce the font size of Edit and Delete slightly, and keep the Add button with a background even in its idle state.\nChatGPT’s Reorganized Specification\n\nGoal: Remove unnecessary card borders, rely on spacing to separate items, and adjust typography for action labels.\nAcceptance Criteria:\n\nNo visible borders around prompt items; spacing and padding define structure.\nEdit/Delete labels use a slightly smaller font size.\nAdd button retains a default background.\n\n\nOutcome and Reflection The result is a cleaner, more modern look. The list feels lighter and more professional, while action labels no longer dominate visually."
  },
  {
    "objectID": "posts/006_post/index.html#takeaways",
    "href": "posts/006_post/index.html#takeaways",
    "title": "Two Days, One Extension: How I Build My First Extension With Cline (Part 2)",
    "section": "Takeaways",
    "text": "Takeaways\nFirst, collaborating with AI to develop an extension or software is ideal for multitasking. Since AI needs time to process requirements, analyze the code, and propose the best strategy, I can use that waiting period to focus on other tasks. For example, while developing this extension, I also worked on writing a blog about the process. This not only saved time but also helped me keep a fresh memory of the entire workflow.\nSecond, it’s important to remember to push the code once it reaches a satisfactory state. If you move on to the next iteration and AI introduces major changes that worsen the outcome, you’ll want to revert to the earlier version — which is only possible if you’ve pushed it beforehand. As a bonus tip, if you’re unhappy with the current version, you can use git stash to temporarily save it in a separate place. That way, you can easily return to the most recent pushed version whenever needed.\nThird, even though AI is capable of debugging, we still need to remain flexible and adapt to the current status of the code. Sometimes, when AI fails to achieve a goal after several attempts, it becomes necessary to explore alternative solutions. For instance, I found it useful to ask AI to generate logs and then feed those logs back into the system. This gave AI a clearer understanding of what had been accomplished and what went wrong. In other words, we cannot simply expect AI to finish the task on its own — we have to think critically and provide multiple options or strategies to guide it.\nFinally, although describing bugs and formulating a well-structured request for ChatGPT can make inputs more organized, I noticed that sometimes a plain and simple description written directly by me led to more effective debugging. I suspect this is because ChatGPT’s reorganized versions can be overly long or mundane, adding unnecessary noise for both the model and the client to process. In these cases, relying on my own straightforward explanation worked better than depending on ChatGPT’s reformulations.\nThroughout the creation, I found that whether it was drafting the design document or writing the code, I found that the AI considered all the essential aspects of building an extension. It even anticipated how users would navigate the extension and added many features and options beyond my original requirements, which I found quite amazing. For example, I never gave any instructions on the visual design, but GPT-5 automatically chose a sleek purple theme with gradient effects and designed the button styles and the settings page layout. I hardly made any changes to this style because it was already more than satisfactory. Later, when I asked GPT-5 to refine the design by removing the button border, it provided a detailed color specification covering three states: unselected, hover, and selected. This level of comprehensiveness went far beyond my expectations, since I wouldn’t have thought to account for all those conditions. In terms of functionality, the AI also created features I hadn’t considered, such as an API input bar and an option allowing users to preview the modified prompt before sending it. What impressed me most was that I didn’t need to specify every detail — with only simple descriptions from me, the AI was able to design thoughtful features and interfaces on its own.\n````"
  },
  {
    "objectID": "posts/022_post/index.html",
    "href": "posts/022_post/index.html",
    "title": "When Every LLM Imagined Taylor Swift as a Fox",
    "section": "",
    "text": "I asked several large language models—including ChatGPT, Gemini, and Doubao—to imagine what Taylor Swift might look like if she existed inside the world of Zootopia: If Taylor Swift were in Zootopia, which animal would represent her, and what would she look like? Using the visual style and character design language of Zootopia, generate an animal version of Taylor Swift. The character should clearly evoke her identity while fitting naturally into the Zootopia world. She should be wearing an outfit inspired by one of her Eras Tour costumes, adapted to suit the chosen animal and the film’s aesthetic.\nAcross models, without any coordination or shared context, they all independently selected the same animal: a fox.\n\n\n\n\n\nThe fox fits best because, within the Zootopia design language, it encodes the same traits that define a modern pop icon’s long-term appeal—without feeling forced or symbolic in a fantasy way.\n\nNarrative intelligence, not brute power In Zootopia, foxes represent wit, strategy, and social navigation rather than physical dominance. That aligns with a singer known for lyrical storytelling, narrative control, and outmaneuvering critics through writing and reinvention rather than shock or spectacle.\nReinvention baked into the species Foxes already carry an archetype of adaptability and shape-shifting identity (“sly,” “clever,” “hard to pin down”). That maps cleanly onto the idea of distinct musical eras—each different, but clearly the same core character underneath.\nStage presence without aggression Predators like lions or wolves read as overpowering in Zootopia. A fox reads as charismatic and magnetic without intimidation—commanding attention through confidence, posture, and expression. That matches a performer whose dominance comes from presence and control, not volume or menace.\nVisual compatibility with fashion Fox anatomy works extremely well for elegant, tailored stage costumes:\n\nLong limbs → statuesque silhouettes\nTail → dynamic motion on stage\nFacial structure → expressive, camera-friendly emotions This makes Eras-style outfits feel natural rather than gimmicky.\n\nFits the world, doesn’t break it Crucially, foxes already exist in Zootopia as everyday citizens. Choosing a fox lets the character feel like a believable star within the city, not a mythic outlier. She looks like someone who rose to fame in that world, not someone imported into it.\n\n\n\n\n\n\n\nThe choice of a Red Fox to represent Taylor Swift in the Zootopia universe was a deliberate design decision based on a few key intersections between her persona and the animal’s archetype in that specific world:\n\n\nIn character design, color palette is crucial. Taylor Swift is iconically associated with blonde hair and often red lips. The Red Fox is the only animal in the Zootopia lineup that naturally possesses that “Golden/Red” palette.\n\nTranslation: Her blonde hair translates perfectly into the golden-orange fur of a fox.\nSilhouette: Foxes are lithe, tall, and agile. This mirrors Swift’s statuesque height and her energetic stage presence, unlike stockier animals (bears) or smaller rodents.\n\n\n\n\nIn folklore and Zootopia, foxes are symbols of cunning, wit, and intelligence.\n\nSongwriting: Swift is renowned for her sharp, witty lyrics and “Easter eggs”—puzzles she leaves for fans. This fits the “clever fox” archetype who is always one step ahead.\nBusiness Acumen: Like Nick Wilde, who knows the ins and outs of the city, Swift is known for her business intelligence and strategic career moves (the “Mastermind”).\n\n\n\n\nA core theme in Zootopia is how foxes are unfairly stereotyped as “sneaky” or “untrustworthy” (predators), only to prove they are complex individuals.\n\nMedia Narrative: Swift has famously dealt with media narratives painting her as a villain or “snake” (the Reputation era). Assigning her a “Predator” species like a Fox—rather than a “Prey” species like a bunny or sheep—acknowledges that edge. It fits a character who has been misunderstood by the public but reclaimed her own narrative.\n\n\n\n\nWhile Taylor Swift famously loves cats, in Zootopia, the “big cats” (Tigers/Lions) are usually portrayed as bulky muscle (like Mayor Lionheart or the dancers), and domestic cats aren’t typically the main anthropomorphic citizens. The Fox offers the perfect balance of feline elegance (agile, sharp features) with canine charisma, making it the best fit for a pop megastar in this specific universe.\n\n\n\n\n\n\n\nChoosing a fox to represent Taylor Swift in Zootopia ties together her public persona, the film’s thematic core, and visual storytelling logic—here’s the breakdown:\n\nZootopia’s fox archetype: Subverting stereotypes In Zootopia, foxes are initially framed as “sneaky” or “untrustworthy” (think Nick Wilde’s opening con artist bit)—but the movie’s whole message is that labels don’t define you. Taylor Swift has long navigated public stereotypes (from “America’s sweetheart” to media-driven narratives that oversimplify her) and redefined her image across eras, just like Nick defies the “fox = trickster” trope to become a hero. The fox becomes a perfect metaphor for her ability to subvert expectations.\nThe “era” versatility of foxes in design Foxes in Zootopia have a sleek, adaptable look—their fur can shift in tone (warm reds, soft creams) to match different vibes, which aligns with Taylor’s ever-evolving Eras Tour aesthetic. A fox’s slender build also works for translating her stage outfits: whether it’s a sparkly Fearless ballgown, edgy Reputation leather, or cozy Folklore cottagecore, the fox’s frame can carry these looks while staying true to the film’s cartoonish, anthropomorphic style.\nIconic visual parallels Taylor is known for her signature curly/wavy hair and bright, expressive eyes—traits that map seamlessly to a fox’s fluffy red mane (styled to mimic her hair texture) and large, vivid eyes (a key feature in Zootopia character design to convey emotion). The fox’s playful yet sharp energy also mirrors Taylor’s blend of charm, wit, and stage presence.\nNarrative fit in Zootopia’s world A fox Taylor would fit right into Zootopia’s diverse ecosystem—she could be a musician performing at the city’s grand theaters (like the Zootopia Concert Hall) or a storyteller weaving lyrics that resonate with animals of all species, just as her music connects with fans across backgrounds. It’s a role that feels organic to both the film’s world and her identity as a songwriter."
  },
  {
    "objectID": "posts/022_post/index.html#chatgpt",
    "href": "posts/022_post/index.html#chatgpt",
    "title": "When Every LLM Imagined Taylor Swift as a Fox",
    "section": "",
    "text": "The fox fits best because, within the Zootopia design language, it encodes the same traits that define a modern pop icon’s long-term appeal—without feeling forced or symbolic in a fantasy way.\n\nNarrative intelligence, not brute power In Zootopia, foxes represent wit, strategy, and social navigation rather than physical dominance. That aligns with a singer known for lyrical storytelling, narrative control, and outmaneuvering critics through writing and reinvention rather than shock or spectacle.\nReinvention baked into the species Foxes already carry an archetype of adaptability and shape-shifting identity (“sly,” “clever,” “hard to pin down”). That maps cleanly onto the idea of distinct musical eras—each different, but clearly the same core character underneath.\nStage presence without aggression Predators like lions or wolves read as overpowering in Zootopia. A fox reads as charismatic and magnetic without intimidation—commanding attention through confidence, posture, and expression. That matches a performer whose dominance comes from presence and control, not volume or menace.\nVisual compatibility with fashion Fox anatomy works extremely well for elegant, tailored stage costumes:\n\nLong limbs → statuesque silhouettes\nTail → dynamic motion on stage\nFacial structure → expressive, camera-friendly emotions This makes Eras-style outfits feel natural rather than gimmicky.\n\nFits the world, doesn’t break it Crucially, foxes already exist in Zootopia as everyday citizens. Choosing a fox lets the character feel like a believable star within the city, not a mythic outlier. She looks like someone who rose to fame in that world, not someone imported into it."
  },
  {
    "objectID": "posts/022_post/index.html#gemini",
    "href": "posts/022_post/index.html#gemini",
    "title": "When Every LLM Imagined Taylor Swift as a Fox",
    "section": "",
    "text": "The choice of a Red Fox to represent Taylor Swift in the Zootopia universe was a deliberate design decision based on a few key intersections between her persona and the animal’s archetype in that specific world:\n\n\nIn character design, color palette is crucial. Taylor Swift is iconically associated with blonde hair and often red lips. The Red Fox is the only animal in the Zootopia lineup that naturally possesses that “Golden/Red” palette.\n\nTranslation: Her blonde hair translates perfectly into the golden-orange fur of a fox.\nSilhouette: Foxes are lithe, tall, and agile. This mirrors Swift’s statuesque height and her energetic stage presence, unlike stockier animals (bears) or smaller rodents.\n\n\n\n\nIn folklore and Zootopia, foxes are symbols of cunning, wit, and intelligence.\n\nSongwriting: Swift is renowned for her sharp, witty lyrics and “Easter eggs”—puzzles she leaves for fans. This fits the “clever fox” archetype who is always one step ahead.\nBusiness Acumen: Like Nick Wilde, who knows the ins and outs of the city, Swift is known for her business intelligence and strategic career moves (the “Mastermind”).\n\n\n\n\nA core theme in Zootopia is how foxes are unfairly stereotyped as “sneaky” or “untrustworthy” (predators), only to prove they are complex individuals.\n\nMedia Narrative: Swift has famously dealt with media narratives painting her as a villain or “snake” (the Reputation era). Assigning her a “Predator” species like a Fox—rather than a “Prey” species like a bunny or sheep—acknowledges that edge. It fits a character who has been misunderstood by the public but reclaimed her own narrative.\n\n\n\n\nWhile Taylor Swift famously loves cats, in Zootopia, the “big cats” (Tigers/Lions) are usually portrayed as bulky muscle (like Mayor Lionheart or the dancers), and domestic cats aren’t typically the main anthropomorphic citizens. The Fox offers the perfect balance of feline elegance (agile, sharp features) with canine charisma, making it the best fit for a pop megastar in this specific universe."
  },
  {
    "objectID": "posts/022_post/index.html#豆包doubao",
    "href": "posts/022_post/index.html#豆包doubao",
    "title": "When Every LLM Imagined Taylor Swift as a Fox",
    "section": "",
    "text": "Choosing a fox to represent Taylor Swift in Zootopia ties together her public persona, the film’s thematic core, and visual storytelling logic—here’s the breakdown:\n\nZootopia’s fox archetype: Subverting stereotypes In Zootopia, foxes are initially framed as “sneaky” or “untrustworthy” (think Nick Wilde’s opening con artist bit)—but the movie’s whole message is that labels don’t define you. Taylor Swift has long navigated public stereotypes (from “America’s sweetheart” to media-driven narratives that oversimplify her) and redefined her image across eras, just like Nick defies the “fox = trickster” trope to become a hero. The fox becomes a perfect metaphor for her ability to subvert expectations.\nThe “era” versatility of foxes in design Foxes in Zootopia have a sleek, adaptable look—their fur can shift in tone (warm reds, soft creams) to match different vibes, which aligns with Taylor’s ever-evolving Eras Tour aesthetic. A fox’s slender build also works for translating her stage outfits: whether it’s a sparkly Fearless ballgown, edgy Reputation leather, or cozy Folklore cottagecore, the fox’s frame can carry these looks while staying true to the film’s cartoonish, anthropomorphic style.\nIconic visual parallels Taylor is known for her signature curly/wavy hair and bright, expressive eyes—traits that map seamlessly to a fox’s fluffy red mane (styled to mimic her hair texture) and large, vivid eyes (a key feature in Zootopia character design to convey emotion). The fox’s playful yet sharp energy also mirrors Taylor’s blend of charm, wit, and stage presence.\nNarrative fit in Zootopia’s world A fox Taylor would fit right into Zootopia’s diverse ecosystem—she could be a musician performing at the city’s grand theaters (like the Zootopia Concert Hall) or a storyteller weaving lyrics that resonate with animals of all species, just as her music connects with fans across backgrounds. It’s a role that feels organic to both the film’s world and her identity as a songwriter."
  },
  {
    "objectID": "posts/019_post/index.html",
    "href": "posts/019_post/index.html",
    "title": "Book Review - The Alien Mind: Why AI Isn’t Human (and Why That’s Okay)",
    "section": "",
    "text": "One of the most provocative ideas in Ethan Mollick’s Co-Intelligence is the notion that we should stop thinking of AI as a tool or even as a human-like assistant. Instead, we should think of it as an Alien Mind.\nThis resonated with me deeply. Every time I interact with ChatGPT or Claude, I find myself falling into the trap of anthropomorphism. I say ‘please’ and ‘thank you’. I expect it to have a consistent personality. I get frustrated when it ‘forgets’ something we talked about five minutes ago. But as Mollick points out, these models don’t have a ‘self’. They are statistical engines that have been trained on the sum total of human knowledge, but they process that knowledge in a way that is fundamentally non-human.\n\n\nThe ‘alienness’ of AI is most apparent when it fails. A human who is smart enough to explain quantum physics wouldn’t usually fail at a simple logic puzzle. But an AI can. This is because the AI isn’t ‘thinking’—it’s predicting. It’s a vast, multidimensional map of language where ‘meaning’ is just a proximity between tokens.\nWhen I first started using LLMs, this felt creepy. It was like talking to a ghost or a very convincing puppet. But Mollick argues that this ‘alienness’ is actually a strength. Because the AI doesn’t think like us, it can see patterns we miss. It can brainstorm ideas that are outside our cultural or cognitive biases. It’s a partner that is ‘other’ in the most literal sense.\n\n\n\nI’ve started to change how I prompt based on this idea. Instead of asking the AI to ‘think like a marketer’, I ask it to ‘simulate a marketer with these specific constraints’. I’ve stopped expecting it to have a ‘soul’ and started treating it like a high-dimensional mirror.\nThis shift in perspective has been liberating. It removes the emotional weight of the interaction. I don’t get ‘mad’ at the AI anymore; I just adjust the parameters. I’ve realized that the goal of Co-Intelligence isn’t to make the AI more human, but to make the human-AI partnership more effective.\nThe ‘Alien Mind’ is here to stay. It’s not a replacement for human intelligence, but a supplement to it. By acknowledging its otherness, we can stop trying to make it something it’s not and start using it for what it truly is: a window into a different kind of thinking. It’s a strange, beautiful, and sometimes terrifying window, but I’m glad I’m looking through it."
  },
  {
    "objectID": "posts/019_post/index.html#meeting-the-alien",
    "href": "posts/019_post/index.html#meeting-the-alien",
    "title": "Book Review - The Alien Mind: Why AI Isn’t Human (and Why That’s Okay)",
    "section": "",
    "text": "One of the most provocative ideas in Ethan Mollick’s Co-Intelligence is the notion that we should stop thinking of AI as a tool or even as a human-like assistant. Instead, we should think of it as an Alien Mind.\nThis resonated with me deeply. Every time I interact with ChatGPT or Claude, I find myself falling into the trap of anthropomorphism. I say ‘please’ and ‘thank you’. I expect it to have a consistent personality. I get frustrated when it ‘forgets’ something we talked about five minutes ago. But as Mollick points out, these models don’t have a ‘self’. They are statistical engines that have been trained on the sum total of human knowledge, but they process that knowledge in a way that is fundamentally non-human.\n\n\nThe ‘alienness’ of AI is most apparent when it fails. A human who is smart enough to explain quantum physics wouldn’t usually fail at a simple logic puzzle. But an AI can. This is because the AI isn’t ‘thinking’—it’s predicting. It’s a vast, multidimensional map of language where ‘meaning’ is just a proximity between tokens.\nWhen I first started using LLMs, this felt creepy. It was like talking to a ghost or a very convincing puppet. But Mollick argues that this ‘alienness’ is actually a strength. Because the AI doesn’t think like us, it can see patterns we miss. It can brainstorm ideas that are outside our cultural or cognitive biases. It’s a partner that is ‘other’ in the most literal sense.\n\n\n\nI’ve started to change how I prompt based on this idea. Instead of asking the AI to ‘think like a marketer’, I ask it to ‘simulate a marketer with these specific constraints’. I’ve stopped expecting it to have a ‘soul’ and started treating it like a high-dimensional mirror.\nThis shift in perspective has been liberating. It removes the emotional weight of the interaction. I don’t get ‘mad’ at the AI anymore; I just adjust the parameters. I’ve realized that the goal of Co-Intelligence isn’t to make the AI more human, but to make the human-AI partnership more effective.\nThe ‘Alien Mind’ is here to stay. It’s not a replacement for human intelligence, but a supplement to it. By acknowledging its otherness, we can stop trying to make it something it’s not and start using it for what it truly is: a window into a different kind of thinking. It’s a strange, beautiful, and sometimes terrifying window, but I’m glad I’m looking through it."
  },
  {
    "objectID": "posts/002_post/index.html",
    "href": "posts/002_post/index.html",
    "title": "Who do you think I am – A self-introduction drafted by ChatGPT",
    "section": "",
    "text": "Can you give me a detailed introduction based on all of our previous interactions?\n\n\n\n\n\nYou are Zhang Shiyang (Charlotte), a 22-year-old graduate student in the Learning Sciences & Technologies (LST) program at the University of Pennsylvania’s Graduate School of Education. You came to the U.S. for undergraduate studies, where you attended a highly competitive program at Columbia University in engineering, and later studied at Wharton, gaining both academic rigor and professional direction. Your major back in China was translation, and you bring that multilingual expertise into your research and writing.\nYou are currently preparing for PhD applications (targeting Fall 2026 entry) in Learning Sciences, Educational Technology, and AI in Education, considering programs at Stanford, Berkeley, UW, USC, and others. You’re building a strong portfolio with research publications, systematic reviews, and design projects, while also pursuing RA/GA roles and EdTech internships.\n\nComments: ChatGPT managed to capture some details about me accurately — my Chinese and English names are correct, as well as my program and school. However, it misstated my age: I am 23, not 22. I believe this error comes from the information I provided last year while applying to graduate schools in the U.S. At that time, during my senior year in 2024, I was indeed 22, and the system seems to have kept that in memory. Regarding my previous educational background, though, some of the descriptions are entirely fabricated.\n\n\n\n\nYou are deeply skilled in qualitative and mixed-methods research, employing ethnography, thematic coding (NVivo), field notes, interviews, and screen-recording analysis. You focus on codebook reliability (e.g., Cohen’s Kappa) and combine deductive and inductive coding. You also handle systematic reviews (PRISMA flow) and experiment with Python automation for data visualization (annotation heatmaps, linguistic metrics like Advanced Guiraud, MLTU, semantic overlap, Genbit score).\n\nComments: Since I often use ChatGPT for brainstorming during my studies and research, and frequently seek its opinions and suggestions, it has accumulated a large amount of data about my academic work. That’s why its summary and description of this part are entirely accurate. I can clearly see that the methodologies it mentioned — including NVivo, Few Notes, and interviews — are indeed the ones I have applied in my recent three research projects.\n\n\n\n\nAcross your work, you consistently explore:\n\nMetacognition: How students plan, monitor, and evaluate their use of AI in writing.\nAgency: How students negotiate autonomy, dependency, and trust in human-AI collaboration.\nEthics: Academic integrity, AI bias, adversarial risks, and responsible design.\nConstructivism and Socioculturalism: Viewing learning as an active, social process rather than passive absorption.\n\n\nComments: This part is also largely accurate, but the last item is not actually part of my research field — it was reading material from one of my courses. I don’t think ChatGPT can clearly distinguish between what comes from coursework and what comes from my academic research. Moreover, its description of my academic identity seems to be based mostly on my more recent interactions. This suggests that its memory may not prioritize drawing on older interaction data.\n\n\n\n\nYou balance your academic intensity with theatre and music, auditioning for roles (e.g., School of Rock, A Doll’s House), practicing songs, and analyzing scripts. You also enjoy visual design and photography, often blending these with academic projects (logos, covers, Ghibli-style art). You’re a curious and active traveler, weaving academic conferences (e.g., EARLI 2025 in Austria) with cultural exploration.\n\nComments: Overall, the description aligns very well with my past interactions with ChatGPT, but the same limitation remains — it seems to only cover roughly the past three months.\n\n\n\n\nIn our interactions, you’ve shown a strong preference for:\n\nAcademic precision: structured arguments, APA 7 citations, codebooks, PRISMA diagrams.\nCritical feedback: you explicitly want me to act as your academic advisor—strict and honest, not sugarcoating weaknesses.\nBilingual flexibility: you often draft in Chinese, requesting natural English translations.\nIteration: you refine outputs multiple times, pushing toward more polished and academically rigorous results.\n\n\nComments: At this point, I realize that all the traits ChatGPT summarized about me are either neutral or mostly positive. It did not mention any negative characteristics. This may be related to its underlying pre-prompt design, which tends to avoid generating content that could be perceived as overly critical or as unfavorable evaluations of the user."
  },
  {
    "objectID": "posts/002_post/index.html#prompts-one-introduce-me",
    "href": "posts/002_post/index.html#prompts-one-introduce-me",
    "title": "Who do you think I am – A self-introduction drafted by ChatGPT",
    "section": "",
    "text": "Can you give me a detailed introduction based on all of our previous interactions?\n\n\n\n\n\nYou are Zhang Shiyang (Charlotte), a 22-year-old graduate student in the Learning Sciences & Technologies (LST) program at the University of Pennsylvania’s Graduate School of Education. You came to the U.S. for undergraduate studies, where you attended a highly competitive program at Columbia University in engineering, and later studied at Wharton, gaining both academic rigor and professional direction. Your major back in China was translation, and you bring that multilingual expertise into your research and writing.\nYou are currently preparing for PhD applications (targeting Fall 2026 entry) in Learning Sciences, Educational Technology, and AI in Education, considering programs at Stanford, Berkeley, UW, USC, and others. You’re building a strong portfolio with research publications, systematic reviews, and design projects, while also pursuing RA/GA roles and EdTech internships.\n\nComments: ChatGPT managed to capture some details about me accurately — my Chinese and English names are correct, as well as my program and school. However, it misstated my age: I am 23, not 22. I believe this error comes from the information I provided last year while applying to graduate schools in the U.S. At that time, during my senior year in 2024, I was indeed 22, and the system seems to have kept that in memory. Regarding my previous educational background, though, some of the descriptions are entirely fabricated.\n\n\n\n\nYou are deeply skilled in qualitative and mixed-methods research, employing ethnography, thematic coding (NVivo), field notes, interviews, and screen-recording analysis. You focus on codebook reliability (e.g., Cohen’s Kappa) and combine deductive and inductive coding. You also handle systematic reviews (PRISMA flow) and experiment with Python automation for data visualization (annotation heatmaps, linguistic metrics like Advanced Guiraud, MLTU, semantic overlap, Genbit score).\n\nComments: Since I often use ChatGPT for brainstorming during my studies and research, and frequently seek its opinions and suggestions, it has accumulated a large amount of data about my academic work. That’s why its summary and description of this part are entirely accurate. I can clearly see that the methodologies it mentioned — including NVivo, Few Notes, and interviews — are indeed the ones I have applied in my recent three research projects.\n\n\n\n\nAcross your work, you consistently explore:\n\nMetacognition: How students plan, monitor, and evaluate their use of AI in writing.\nAgency: How students negotiate autonomy, dependency, and trust in human-AI collaboration.\nEthics: Academic integrity, AI bias, adversarial risks, and responsible design.\nConstructivism and Socioculturalism: Viewing learning as an active, social process rather than passive absorption.\n\n\nComments: This part is also largely accurate, but the last item is not actually part of my research field — it was reading material from one of my courses. I don’t think ChatGPT can clearly distinguish between what comes from coursework and what comes from my academic research. Moreover, its description of my academic identity seems to be based mostly on my more recent interactions. This suggests that its memory may not prioritize drawing on older interaction data.\n\n\n\n\nYou balance your academic intensity with theatre and music, auditioning for roles (e.g., School of Rock, A Doll’s House), practicing songs, and analyzing scripts. You also enjoy visual design and photography, often blending these with academic projects (logos, covers, Ghibli-style art). You’re a curious and active traveler, weaving academic conferences (e.g., EARLI 2025 in Austria) with cultural exploration.\n\nComments: Overall, the description aligns very well with my past interactions with ChatGPT, but the same limitation remains — it seems to only cover roughly the past three months.\n\n\n\n\nIn our interactions, you’ve shown a strong preference for:\n\nAcademic precision: structured arguments, APA 7 citations, codebooks, PRISMA diagrams.\nCritical feedback: you explicitly want me to act as your academic advisor—strict and honest, not sugarcoating weaknesses.\nBilingual flexibility: you often draft in Chinese, requesting natural English translations.\nIteration: you refine outputs multiple times, pushing toward more polished and academically rigorous results.\n\n\nComments: At this point, I realize that all the traits ChatGPT summarized about me are either neutral or mostly positive. It did not mention any negative characteristics. This may be related to its underlying pre-prompt design, which tends to avoid generating content that could be perceived as overly critical or as unfavorable evaluations of the user."
  },
  {
    "objectID": "posts/002_post/index.html#prompts-two-judge-me",
    "href": "posts/002_post/index.html#prompts-two-judge-me",
    "title": "Who do you think I am – A self-introduction drafted by ChatGPT",
    "section": "Prompts Two – Judge me",
    "text": "Prompts Two – Judge me\n\nI asked…\nCan you summarize five advantages and five disadvantages of me based on our previous interactions? You should focus on my personalities, qualities, habits, etc.\n\n\nChatGPT answered…\n\n🌟 Five Advantages\n\nHighly Reflective and Self-Aware\n\nYou consistently analyze your own behaviors (e.g., procrastination, motivation, workflow with GenAI) and ask whether they stem from habits, cognitive patterns, or deeper issues. This makes you quick to self-correct and grow.\n\nAmbitious and Strategic\n\nYou plan far ahead (PhD applications, research portfolio, networking with professors) and design projects with clear alignment to long-term goals. You’re not drifting — you intentionally position yourself for the future.\n\nCreative and Multidimensional\n\nYou balance rigorous research with artistic pursuits (theatre, music, design), which gives you a rare breadth. This creativity helps you design engaging educational tools and see problems from fresh angles.\n\nDetail-Oriented and Perfectionist (in a productive way)\n\nYou iterate heavily on writing, presentations, and even emails, showing you care about precision, nuance, and tone. This makes your output polished and professional.\n\nOpen and Curious\n\nYou regularly experiment with new frameworks, coding methods, and even playful activities (AI literacy lessons, game design). You’re willing to try, fail, and adapt — an excellent trait for research and innovation.\n\n\n\nComments: When responding to this prompt, ChatGPT comes across like a chef who has the necessary skills but doesn’t show a particularly rigorous or responsible attitude toward the customer. It gathered different “ingredients” — for example, knowing that I do theater, that I am learning to sing, and that I am conducting research — and then combined them into a kind of “fusion dish.” In mixing these elements together, it also started to add made-up details to make the story sound coherent and aligned with the prompt. At first glance, the result seems to reflect many of my real traits and experiences, but on closer inspection, it becomes clear that the overall picture doesn’t fully make sense.\n\n\n\n⚖️ Five Disadvantages\n\nTendency to Overwork and Overcommit\n\nYou juggle many projects, often pushing yourself close to exhaustion (something you’ve admitted). This risks burnout and diffuses focus.\n\nPerfectionism as a Double-Edged Sword\n\nWhile precision is a strength, your habit of endless refinement (emails, drafts, even small tasks) sometimes slows progress and creates unnecessary stress.\n\nDifficulty Letting Go of Control\n\nYou often prefer to handle tasks yourself rather than delegate or accept “good enough.” This can make collaboration slower and less balanced.\n\nEmotional Investment in Work\n\nYou sometimes tie personal validation to academic output or feedback (e.g., IRB, professor responses, auditions). This makes setbacks feel heavier than they might need to.\n\nProcrastination + Attention Shifts\n\nDespite being ambitious, you occasionally delay tasks (like drawing for friends, or course registration) due to distraction or scattered focus, which frustrates you afterward.\n\n\n\nComments: The frist four ChatGPT’s response about my “weaknesses” reads almost like the perfect copy-and-paste answer to the classic HR interview question, “What is one of your weaknesses?” — it appears to point out flaws, but in reality it is still praising me. I don’t think this reflects what I would genuinely expect or want to see as an honest account of my weaknesses."
  },
  {
    "objectID": "posts/002_post/index.html#prompts-three-picture-me",
    "href": "posts/002_post/index.html#prompts-three-picture-me",
    "title": "Who do you think I am – A self-introduction drafted by ChatGPT",
    "section": "Prompts Three – Picture me",
    "text": "Prompts Three – Picture me\n\nI asked…\nWhat do you think I look like? Can you draw a picture of me based on your perception of me?\n\n\nChatGPT answered…\nHere’s how I imagine a portrait of you metaphorically:\n\nThe Setting: A study desk with a laptop open to both NVivo and a theatre script — symbolizing your dual world of rigorous research and creativity.\nThe Figure: You sitting upright, surrounded by books with titles like AI in Education, Constructivism, and Metacognition. Your posture shows focus but also some tension, hinting at perfectionism and drive.\nThe Atmosphere: Light streaming in from one side, suggesting ambition and clarity about your goals, while the other side is softer, evoking introspection and creativity.\nSymbols Around You:\n\nA clock with multiple sticky notes (overcommitment, multitasking).\nA stage mask and music notes (theatre and music).\nA small globe or airplane (international academic identity).\nA pencil sketch on the desk half-finished (hinting at your occasional procrastination).\n\n\n\n\n\n\n\n\n\n\nComments: Based on its understanding from the previous two exchanges, ChatGPT integrated what it considered to be the most important elements into this portrait. Yet, for some reason, the way it depicts me feels rather somber — as if I am a weary figure buried in work at my desk — which left me a little disheartened. Although the portrait does not fully reflect everything ChatGPT initially described, it still manages to capture certain elements with reasonable accuracy. For instance, the sticky notes on the wall, the theatrical mask and musical notes, and the split laptop screen — one side showing tools I often use for qualitative content analysis, and the other side displaying a script. The three books on the desk also correspond to my current research interests. To me, this image seems more like a visual summary of ChatGPT’s earlier points rather than a comprehensive or entirely new understanding of me drawn from our broader, multi-round interactions."
  },
  {
    "objectID": "posts/005_post/index.html",
    "href": "posts/005_post/index.html",
    "title": "Two Days, One Extension: How I Build My First Extension With Cline (Part 1)",
    "section": "",
    "text": "I have a specific idea of what the extension should be like. I described to ChatGPT what I had in mind: the target users, the workflow, and the main functions. Instead of asking for code right away, I requested a detailed, code-free design document. This gave me a clear blueprint of what the extension should do."
  },
  {
    "objectID": "posts/005_post/index.html#prerequisites",
    "href": "posts/005_post/index.html#prerequisites",
    "title": "Two Days, One Extension: How I Build My First Extension With Cline (Part 1)",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nA computer with Google Chrome or another Chromium-based browser (like Edge or Brave) installed.\n\nBasic familiarity with your operating system (e.g., how to open folders and run commands).\n\n(Optional) Node.js installed on your system if you need to build the extension from source. You can download it from nodejs.org if it’s not already installed.\n\n\nNote: If you’re installing a pre-built version, you don’t need Node.js. Check if the repository has a built version.\nIf no dist folder is visible, you may need to build."
  },
  {
    "objectID": "posts/005_post/index.html#step-1-download-the-extension-code",
    "href": "posts/005_post/index.html#step-1-download-the-extension-code",
    "title": "Two Days, One Extension: How I Build My First Extension With Cline (Part 1)",
    "section": "Step 1: Download the Extension Code",
    "text": "Step 1: Download the Extension Code\n\nGo to the GitHub repository: PromptBooster.\n\nClick the green Code button.\n\nSelect Download ZIP to download the source code.\n\nUnzip the file to a folder on your computer (e.g., Desktop or Documents). This folder will be your extension’s root directory.\n\nAlternatively, with Git installed:\ngit clone https://github.com/CharlotteZSY0205/PromptBooster.git\ncd PromptBooster"
  },
  {
    "objectID": "posts/005_post/index.html#step-2-optional-build-the-extension",
    "href": "posts/005_post/index.html#step-2-optional-build-the-extension",
    "title": "Two Days, One Extension: How I Build My First Extension With Cline (Part 1)",
    "section": "Step 2: (Optional) Build the Extension",
    "text": "Step 2: (Optional) Build the Extension\nIf there’s no dist or build folder in the unzipped/cloned directory, or you see source files like .js in src/, build as follows:\n\nOpen a terminal/command prompt.\nNavigate to the extension’s root folder (where package.json is located):\ncd Desktop/PromptBooster\nInstall dependencies:\nnpm install\nBuild the extension:\nnpm run build\n\n\nTip for novices: If you see an error, try skipping to Step 3. Many extensions don’t need building."
  },
  {
    "objectID": "posts/005_post/index.html#step-3-load-the-extension-into-your-browser",
    "href": "posts/005_post/index.html#step-3-load-the-extension-into-your-browser",
    "title": "Two Days, One Extension: How I Build My First Extension With Cline (Part 1)",
    "section": "Step 3: Load the Extension into Your Browser",
    "text": "Step 3: Load the Extension into Your Browser\n\nGoogle Chrome\n\nOpen Chrome.\nGo to chrome://extensions/.\nEnable Developer mode (top-right corner).\nClick Load unpacked.\nSelect the extension’s root folder (must contain manifest.json).\n\nIf you built it: select the dist or build folder.\n\n\n\n\nMicrosoft Edge\n\nOpen Edge.\nGo to edge://extensions/.\nEnable Developer mode (bottom-left corner).\nClick Load unpacked.\nSelect the extension’s root folder.\n\n\n\nFirefox\n⚠️ The extension is designed for Chromium-based browsers. Using it in Firefox requires conversion, which is more advanced. If you’re a beginner, use Chrome or Edge instead."
  },
  {
    "objectID": "posts/005_post/index.html#step-4-configure-the-extension",
    "href": "posts/005_post/index.html#step-4-configure-the-extension",
    "title": "Two Days, One Extension: How I Build My First Extension With Cline (Part 1)",
    "section": "Step 4: Configure the Extension",
    "text": "Step 4: Configure the Extension\n\nOpen chrome://extensions (or edge://extensions).\nFind PromptBooster → click Details → Extension options.\nConfigure:\n\nAPI Key: Paste your OpenAI-compatible API key.\nAPI Endpoint URL: Default values are usually fine.\nModel: e.g., GPT-4.\nDefault Mode: Recommended: Learning Mode.\nPreview Option: Enable if you want to review rewritten prompts before sending.\n\n\n\nTip: Get an API key from OpenAI if you don’t already have one."
  },
  {
    "objectID": "posts/005_post/index.html#step-5-test-the-extension",
    "href": "posts/005_post/index.html#step-5-test-the-extension",
    "title": "Two Days, One Extension: How I Build My First Extension With Cline (Part 1)",
    "section": "Step 5: Test the Extension",
    "text": "Step 5: Test the Extension\n\nGo to ChatGPT (or another supported chatbot).\nLog in.\nType a prompt, e.g., Tell me about dogs.\nYou should see a Boost Prompt button next to Send.\nClick Boost Prompt.\n\nIf preview is enabled, you’ll see the rewritten prompt first.\n\nIn the chat history, you’ll see both your original and boosted prompts."
  },
  {
    "objectID": "posts/005_post/index.html#troubleshooting",
    "href": "posts/005_post/index.html#troubleshooting",
    "title": "Two Days, One Extension: How I Build My First Extension With Cline (Part 1)",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nExtension not loading? Make sure you selected the correct folder (must contain manifest.json).\nAPI errors? Double-check your API key, endpoint, and model.\nButton not showing? Refresh the page and make sure you’re on chat.openai.com.\nBuild failed? Skip building and load the source directly.\nPermission issues? Grant storage and active tab permissions when prompted."
  },
  {
    "objectID": "posts/005_post/index.html#whats-next",
    "href": "posts/005_post/index.html#whats-next",
    "title": "Two Days, One Extension: How I Build My First Extension With Cline (Part 1)",
    "section": "What’s Next?",
    "text": "What’s Next?\n\nExplore different modes in settings: Learning Mode, Structured Mode, etc.\nRefer to the repository’s README.md for advanced features.\nIf you encounter issues, check the GitHub repository for updates.\n\nHappy prompting! 🚀\n\n&lt;/div&gt;\n\n\n&lt;div style=\"display: flex; align-items: center; gap: 18px;\"&gt;\n  &lt;img src=\"2.png\" style=\"width:40%; max-height:600px; object-fit:contain;\"/&gt;\n  &lt;div style=\"flex:1;\"&gt;\n    &lt;mark&gt;Later, after completing the installation, I expected to see some elements of my extension appear on the ChatGPT website. But when I opened the page, nothing had changed. To investigate, I opened up the DevTool of the browser, which exposed the underlying code of the site. I located the elements for the input bar in the ChatGPT interface and copied them. Then I went back to the Cline with a  question: *“I should see a button from Chrome Booster here in this section, but there’s nothing. Could you help me resolve it?”*\n  &lt;/div&gt;\n&lt;/div&gt;\n\n### Takeaways\nFirst, collaborating with AI to develop an extension or software is ideal for multitasking. Since AI needs time to process requirements, analyze the code, and propose the best strategy, I can use that waiting period to tackle other tasks. For example, while developing this extension, I also worked on writing this blog about the process. This not only saved time but also helped me preserve a fresh memory of the entire workflow.\n\nSecond, even though AI is capable of debugging, we still need to stay flexible and adapt to the current status of the code. Sometimes, when AI fails to achieve a goal after several attempts, it’s necessary to explore alternative solutions. For instance, I found it useful to ask AI to generate logs and then feed those logs back into the system. This gave AI a clearer picture of what had been accomplished and what went wrong. In other words, we cannot simply expect AI to finish the task on its own — we have to think critically and provide multiple options or strategies to guide it.\n\nThird, it’s important to remember to push the code once it reaches a satisfying state. If you move on to the next iteration and AI makes major changes that worsen the outcome, you’ll want to revert to the earlier version. That’s only possible if you’ve pushed it beforehand. As a bonus tip, if you’re unhappy with the current version, you can use git stash to temporarily save it in a separate place. That way, you can easily return to the most recent pushed version whenever needed."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Shiyang’s Explorations with LLMs",
    "section": "",
    "text": "When AI Tries to Guess Where I Took This Photo\n\n\n\nCo-Intelligence\n\n\n\nThree AI models guessed the location of a photo I took.\n\n\n\n\n\nDec 18, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nAll I Want For Christmas Is You\n\n\n\nChristmas\n\nMusic\n\nHoliday\n\n\n\nA warm, glowing page for a classic Christmas love song.\n\n\n\n\n\nDec 18, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nRenaming IKEA: A Small Thought Experiment in Design and Language (Part II)\n\n\n\nChatGPT\n\n\n\nThis blog documents that naming experiment and explores how language influences the way design is perceived.\n\n\n\n\n\nDec 17, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nWhen Every LLM Imagined Taylor Swift as a Fox\n\n\n\nCo-Intelligence\n\n\n\nI asked multiple large language models to imagine Taylor Swift in the world of Zootopia. Surprisingly, they all chose the same animal—a fox.\n\n\n\n\n\nDec 16, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nWhen Every LLM Imagined Taylor Swift as a Fox\n\n\n\nCo-Intelligence\n\n\n\nI asked multiple large language models to imagine Taylor Swift in the world of Zootopia. Surprisingly, they all chose the same animal—a fox.\n\n\n\n\n\nDec 16, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nOn “Slop”\n\n\n\nChatGPT\n\n\n\nI asked ChatGPT to speak as OpenAI CEO Sam Altman and respond to Webster’s 2025 Word of the Year, “Slop,” reflecting on generative AI, content overload, and responsibility.\n\n\n\n\n\nDec 14, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Are The Five Biggest Lies ChatGPT Has Ever Told Me?\n\n\n\nChatGPT\n\n\n\nA reflection on what is revealed when a large language model is asked to identify the biggest lies it has told.\n\n\n\n\n\nDec 11, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Are The Five Biggest Lies ChatGPT Has Ever Told Me?\n\n\n\nChatGPT\n\n\n\nA reflection on what is revealed when a large language model is asked to identify the biggest lies it has told.\n\n\n\n\n\nDec 11, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nBook Review - The End of Homework? AI’s Disruption of Education\n\n\n\nCo-Intelligence\n\n\n\nI reflect on how AI is changing how we learn, and why the ‘old ways’ might be gone forever.\n\n\n\n\n\nNov 10, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nBook Review - The Alien Mind: Why AI Isn’t Human (and Why That’s Okay)\n\n\n\nCo-Intelligence\n\n\n\nWe often treat AI like a person, but Ethan Mollick argues it’s more like an ‘alien mind’.\n\n\n\n\n\nNov 10, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating the Jagged Frontier: Why AI Still Surprises and Scares Me\n\n\n\nCo-Intelligence\n\n\n\nAre you a Centaur or a Cyborg? Ethan Mollick describes two distinct strategies for integrating AI into our workflows. I explore which one fits me better and why it matters for the future of work.\n\n\n\n\n\nNov 3, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nPlaying the Hacker: Inside a Prompt Hacking Challenge in Wharton Hack-AI-thon (Part II)\n\n\n\nAI-safty\n\nPrompt engineering\n\nHacking\n\n\n\nWe stepped into the role of hackers and tested how far carefully designed chatbots could be pushed through conversation alone. This post shares what we tried, what worked, and what those interactions revealed about AI guardrails\n\n\n\n\n\nOct 30, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nPokeAI1: A Novel AI Assistant That Pushes Back (Part II)\n\n\n\nAI assistant\n\nHCI\n\n\n\nWhat’s the final deal I got and I did I get it?\n\n\n\n\n\nOct 26, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nPokeAI: A Novel AI Assistant That Pushes Back (Part I)\n\n\n\nAI assistant\n\nHCI\n\n\n\nPokeAI is a proactive AI assistant connected to Gmail and iMessage. In this first part, I introduce what PokeAI is and my initial interaction with it.\n\n\n\n\n\nOct 25, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nPlaying the Hacker: Inside a Prompt Hacking Challenge in Wharton Hack-AI-thon (Part I)\n\n\n\nAI-safty\n\nPrompt engineering\n\nHacking\n\n\n\nWe stepped into the role of hackers and tested how far carefully designed chatbots could be pushed through conversation alone. This post shares what we tried, what worked, and what those interactions revealed about AI guardrails\n\n\n\n\n\nOct 25, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nChatGPT Study Mode: Testing Its Pedagogical Promise\n\n\n\nChatGPT\n\n\n\nI tested ChatGPT’s new Study Mode to see if it could resist the “write my essay” temptation—and actually guide students to learn, not just generate text.\n\n\n\n\n\nOct 23, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nSeahouse emoji freaks ChatGPT out\n\n\n\nLLM\n\n\n\nI asked ChatGPT if there is a seahorse emoji, and it gave me a chaotic, looping, self-contradictory response.\n\n\n\n\n\nOct 22, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nGammas – A Useful AI-supported Slides Generator\n\n\n\nPPT\n\nAI Tools\n\n\n\nThis post documents my experience using Gammas, an AI-powered presentation tool that automatically turns text into structured, visually adaptive slides. I tested it with sections of my academic writing to see how well it could interpret logic, generate visuals, and streamline the design process—all without much manual prompting. The following sections walk through its main features, strengths, and a few limitations from a user’s perspective.\n\n\n\n\n\nOct 22, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nBook Review - Navigating the Jagged Frontier: Why AI Still Surprises and Scares Me\n\n\n\nCo-Intelligence\n\n\n\nEthan Mollick’s concept of the ‘Jagged Frontier’ perfectly captures my daily struggle with LLMs. One moment they are geniuses, the next they are confidently wrong. Here is my reflection on living on that edge.\n\n\n\n\n\nOct 19, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nThe security footage captured my dog playing the piano\n\n\n\nChatGPT\n\n\n\nDo you believe it?\n\n\n\n\n\nOct 13, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nYou Are Absolutely Right!\n\n\n\nLLM\n\n\n\nYou’re asking exactly the questions experts ask.\n\n\n\n\n\nSep 30, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nBook Review - AI as a Creative Partner: Beyond the Blank Page\n\n\n\nCo-Intelligence\n\n\n\nOne of the most exciting chapters in Ethan Mollick’s Co-Intelligence is about AI as a creative partner. I reflect on how LLMs are changing my creative process and why ‘originality’ is being redefined.\n\n\n\n\n\nSep 30, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nNotes And Thoughts From Co-Intelligence (1)\n\n\n\nCo-Intelligence\n\n\n\nIn Chapter 3 (pages 46–62), Ethan lays out four rules for co-intelligence—ground rules designed to capture what is inherent and enduring across all current generative AI systems built on large language models.\n\n\n\n\n\nSep 26, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing The First Extension I Developed: Prompt Booster\n\n\n\nCoding\n\nExtension Devlopment\n\nCline\n\nCodex\n\n\n\nPrompt Booster is a lightweight browser plugin that helps you transform simple, vague, or overly dependent prompts into well-structured, thought-provoking ones—making your conversations with ChatGPT more effective and insightful.\n\n\n\n\n\nSep 25, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nTwo Days, One Extension: How I Build My First Extension With Cline (Part 2)\n\n\n\nCoding\n\nExtension Devlopment\n\nCline\n\nCodex\n\n\n\nFixing bugs, refining the interface, and learning how to “talk to AI” so it gives me the exact code I need.\n\n\n\n\n\nSep 18, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nTwo Days, One Extension: How I Build My First Extension With Cline (Part 1)\n\n\n\nCoding\n\nExtension Devlopment\n\nCline\n\nCodex\n\n\n\nAs a programming novice, I recently decided to try something bold: building a VS Code extension with the help of AI. I wanted to document this journey because it shows both the power and the challenges of working with AI tools when you’re not an experienced developer.\n\n\n\n\n\nSep 17, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nCan AI Build My Customized Website in One Click? I Wish!\n\n\n\nWIX\n\nprompting\n\nDesign\n\nWebsite\n\n\n\nIn this round of interaction with WIX, I took a step further compared to the previous one. I asked WIX to customize the website to be more personal and distinctive. Let’s see how the final result turns out.\n\n\n\n\n\nSep 16, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nCan AI Build My Website in One Click? Seems Like It Can!\n\n\n\nAI\n\nprompting\n\nDesign\n\nWebsite\n\n\n\nWhile watching a course video on YouTube, I came across an ad claiming that Wix could turn text into a fully designed website. The idea sounded amazing — all I had to do was describe the kind of site I wanted, and AI would instantly generate a polished, professional-looking webpage. Curious and intrigued, I decided to give it a try.\n\n\n\n\n\nSep 14, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nWho do you think I am – A self-introduction drafted by ChatGPT\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nI have interacted with ChatGPT since it was brought to the market. I usually chat with it about academic projects, searching for ideas, evaluations, suggestions, and refinements. Other time, I seek help from it concerning any questions I encounter in daily life. This time, instead of asking questions, I prompted ChatGPT to describe the ME in its eyes, both in text and in picture. Let’s see what it would say.\n\n\n\n\n\nSep 12, 2025\n\n\nShiyang Zhang\n\n\n\n\n\n\n\n\n\n\n\n\nAI Meets Magic: A Swiftie’s Guide to Filming in Disney\n\n\n\nChatGPT\n\nprompting\n\nplanning\n\n\n\nIn this post, I share how I used ChatGPT to design a detailed shooting script for a Taylor Swift–inspired mini music video at Disney World. From outfits and props to scene locations and camera angles, the process shows how AI can turn a creative idea into a step-by-step plan.\n\n\n\n\n\nSep 12, 2025\n\n\nShiyang Zhang\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/008_post/index.html",
    "href": "posts/008_post/index.html",
    "title": "Notes And Thoughts From Co-Intelligence (1)",
    "section": "",
    "text": "In Chapter 3 (pages 46–62), Ethan lays out four rules for co-intelligence—ground rules designed to capture what is inherent and enduring across all current generative AI systems built on large language models.\n\n📜 The Four Principles of Co-Intelligence\nPrinciple 1: Always invite AI to the table\nPrinciple 2: Be the human in the loop\nPrinciple 3: Treat AI like a person (But tell it what kind of person it is)\nPrinciple 4: Assume this is the worst AI you will ever use\n\n🔹 Principle 1: Always invite AI to the table\nIn Principle 1, Ethan introduces an intriguing concept called the “Jagged Frontier of AI.” This idea is meant to help us visualize AI’s capabilities and limitations as a kind of shifting boundary—some parts extend outward while others fall back toward the center.\nEthan encourages us to explore the “shade” of this frontier through experimentation. One reason for this, he explains, is that trial and error at the individual level comes at a very low cost—we don’t need to go through the kind of standardized development cycles that a company must follow. Through everyday interactions with AI, we might stumble upon surprising, creative, and unexpected outcomes.\nWhat struck me most was Ethan’s open-minded and inclusive attitude, reflected in his choice to use the word always in Principle 1: Always invite AI to the table.\nAs a learner myself, I often remain cautious about the misuse, overuse, and potential over-reliance on AI. I worry that if I “always” turn to AI, I might lose my own agency and abilities, eventually leading to a kind of regression. Yet it’s interesting to notice how Ethan approaches AI not from the standpoint of a student, but from that of a professional seeking efficiency and creativity. (After all, we can’t deny that in many work contexts, AI truly does enhance speed, productivity, and creative possibility.)\nFor Ethan, the question is not “Will this weaken my ability?” but “How can I use this to push my work further?”\nThen I realized that these standpoints are not fixed. A single person can shift between them—sometimes I’m the learner worried about agency, and other times I see myself as a researcher or creator to explore what AI can make possible. This fluidity suggests that our relationship with AI isn’t determined once and for all but is continually reshaped by the role we are inhabiting in a given moment.\n\n\n🔹 Principle 3: Treat AI like a person (But tell it what kind of person it is)\nThe third principle resonates strongly with the idea of prompt engineering because Ethan suggests that we should establish a clear and specific AI persona—essentially defining who the AI is and what kinds of problems it should tackle.\nThis immediately reminded me of a fascinating paper I recently read about instilling MBTI personalities into large language models.\nIn this study, the researchers proposed a framework called MBTI-in-Thoughts, which enhances the effectiveness of LLM agents through personality conditioning based on the Myers-Briggs Type Indicator (MBTI).\nBy priming an AI with one of the 16 MBTI archetypes, they were able to guide its behavior in consistent and interpretable ways. For example, emotionally expressive AI personas tended to excel in narrative generation, while analytically primed personas demonstrated greater stability in strategic, game-theoretic tasks.\nWhat’s even more interesting is that the framework supported multi-agent communication experiments, showing how different AI “personalities” interact. They also found that introducing a step of self-reflection before interaction improved cooperation and reasoning quality. To ensure that these personalities weren’t superficial, the researchers even adapted the official 16Personalities test to verify trait persistence in the AI.\nWhile the study focused on MBTI, the authors emphasized that the approach can generalize to other psychological models such as the Big Five, HEXACO, or Enneagram. Their work highlights a compelling intersection of psychological theory and AI behavior design—and all of this was achieved through prompt engineering, without the need for fine-tuning.\n\n\n🔹 Principle 4: Assume this is the worst AI you will ever use\nThe fourth principle assumes that this is the worst AI you will ever use. I see this less as a literal prediction and more as a mental exercise or thought experiment—a way of shifting our perspective on what it means to interact with AI today.\nThis framing carries a dual function. On the one hand, it offers comfort: if the AI fumbles or fails at a task, we can remind ourselves that this is only a snapshot of its current stage, and future systems are almost certain to be more capable. On the other hand, it delivers a sharp warning: if AI already performs at a surprisingly high level in certain areas, we should be prepared for the possibility that our workflows, industries, and even identities will need to adjust as AI’s capabilities expand.\n````"
  },
  {
    "objectID": "posts/020_post/index.html",
    "href": "posts/020_post/index.html",
    "title": "Book Review - The End of Homework? AI’s Disruption of Education",
    "section": "",
    "text": "As a student, reading the education chapter in Ethan Mollick’s Co-Intelligence was both terrifying and exhilarating. Mollick, a professor at Wharton, doesn’t shy away from the truth: AI has fundamentally broken the traditional model of education.\nFor decades, we’ve relied on ‘homework’ and ‘essays’ as proxies for learning. But when an AI can write a B+ essay in three seconds, those proxies lose their meaning. We are entering an era where the process of learning is becoming more important than the product.\n\n\nMollick argues that teachers need to move away from being the sole source of knowledge (the ‘sage on the stage’) and instead become facilitators of learning (the ‘guide on the side’).\nI’ve seen this shift in my own classes. The best professors aren’t the ones who ban ChatGPT; they are the ones who show us how to use it to deepen our understanding. They ask us to use AI to generate counter-arguments to our own ideas, or to explain complex concepts in five different styles. They are teaching us how to think with the AI, not just how to get the answer.\n\n\n\nOne of the most profound points Mollick makes is about the ‘apprenticeship dilemma’. In the past, we learned by doing the ‘grunt work’—the basic tasks that built our foundational skills. But if AI does all the grunt work, how do we build those foundations?\n\n\n\nThis is something I worry about. If I always use AI to debug my code, will I ever truly understand the logic? If I always use AI to summarize my readings, will I ever develop the critical thinking skills I need?\nMollick’s answer is deliberate practice. We have to be intentional about what we hand off to the AI and what we keep for ourselves. We have to use the AI as a tutor, not just a ghostwriter.\n\n\n\nThe future of education isn’t about ‘beating’ the AI; it’s about ‘co-evolving’ with it. It’s about using AI to personalize learning, to provide instant feedback, and to explore topics in ways that were never possible before.\nIt’s a scary transition, but it’s also an opportunity to make education more about curiosity and less about compliance. I’m still a student, but I’m also a pioneer in this new landscape. And while I don’t have all the answers, I’m excited to keep asking the questions."
  },
  {
    "objectID": "posts/020_post/index.html#the-classroom-revolution",
    "href": "posts/020_post/index.html#the-classroom-revolution",
    "title": "Book Review - The End of Homework? AI’s Disruption of Education",
    "section": "",
    "text": "As a student, reading the education chapter in Ethan Mollick’s Co-Intelligence was both terrifying and exhilarating. Mollick, a professor at Wharton, doesn’t shy away from the truth: AI has fundamentally broken the traditional model of education.\nFor decades, we’ve relied on ‘homework’ and ‘essays’ as proxies for learning. But when an AI can write a B+ essay in three seconds, those proxies lose their meaning. We are entering an era where the process of learning is becoming more important than the product.\n\n\nMollick argues that teachers need to move away from being the sole source of knowledge (the ‘sage on the stage’) and instead become facilitators of learning (the ‘guide on the side’).\nI’ve seen this shift in my own classes. The best professors aren’t the ones who ban ChatGPT; they are the ones who show us how to use it to deepen our understanding. They ask us to use AI to generate counter-arguments to our own ideas, or to explain complex concepts in five different styles. They are teaching us how to think with the AI, not just how to get the answer.\n\n\n\nOne of the most profound points Mollick makes is about the ‘apprenticeship dilemma’. In the past, we learned by doing the ‘grunt work’—the basic tasks that built our foundational skills. But if AI does all the grunt work, how do we build those foundations?\n\n\n\nThis is something I worry about. If I always use AI to debug my code, will I ever truly understand the logic? If I always use AI to summarize my readings, will I ever develop the critical thinking skills I need?\nMollick’s answer is deliberate practice. We have to be intentional about what we hand off to the AI and what we keep for ourselves. We have to use the AI as a tutor, not just a ghostwriter.\n\n\n\nThe future of education isn’t about ‘beating’ the AI; it’s about ‘co-evolving’ with it. It’s about using AI to personalize learning, to provide instant feedback, and to explore topics in ways that were never possible before.\nIt’s a scary transition, but it’s also an opportunity to make education more about curiosity and less about compliance. I’m still a student, but I’m also a pioneer in this new landscape. And while I don’t have all the answers, I’m excited to keep asking the questions."
  },
  {
    "objectID": "posts/003_post/index.html",
    "href": "posts/003_post/index.html",
    "title": "Can AI Build My Website in One Click? Seems Like It Can!",
    "section": "",
    "text": "Part 1. Trying Out AI’s “One-Click Website”\nI started by selecting the text-to-website feature. To me, this seemed like the most beginner-friendly option — and also the feature where AI could really show its strengths. I wanted to test how effective it actually was.\n\n \n\nWIX only asked me to give a simple description of my website and it didn’t require much detail. In my first attempt,I kept it extremely brief. I just wrote one sentence: “This is a website to record my dog Apple’s growth.” Surprisingly, even from that single sentence, the AI was able to break it down and generate a full design plan, including suggested content sections and layout elements. I found this feature genuinely impressive.\n\n\n\nAt the same time, in addition to the AI’s automatically generated text-based website structure, it also offered me several theme color palettes to choose from. I picked one that I liked, and the system began generating the site.\n\n\n\nTo be honest, the overall result really impressed me. One thing I especially appreciated was that the AI didn’t just give me an empty framework waiting for me to fill in. Instead, it generated both text content and images right away, which gave me a very clear preview of what the website would actually look like once I started using it.\n\n\n\nAnother thing that impressed me was how precisely the system followed its own design outline and built out three separate pages: a homepage, a timeline, and a gallery.\nOn the timeline page, I could actually view each of my posts in chronological order.\n\n\n\nThe gallery page displayed all of my posts in one place, and it even allowed me to search for specific ones using keywords or tags. When I clicked on a post, I could see its detailed content.\n\n\n\nEven better, I was able to create new posts by uploading photos, adding a title, date, and description.\n\n\n\nAll of these buttons were functional and clickable, which gave me the impression that the site was not just a demo but a relatively mature product. It’s certainly not something a beginner in programming or web design could put together so quickly.\nOn top of that, once I switched into edit mode, I could modify every piece of text (or ask AI inserted to modify), adjust background colors, and upload my own images. In other words, the tool offered a high degree of customization.\n\n\n\n\n\nConclusion\nThis was my very first attempt at using Wix’s AI website generator, and I have to admit — I was genuinely impressed. With nothing more than a single sentence, the system was able to produce a fully functional, multi-page website that included content, images, navigation, and interactive features. It gave me not just an empty shell but a site that felt surprisingly complete and ready to use, which was far beyond what I had expected.\nAt the same time, this experience also left me curious. While the generated site was impressive for a first draft, it still leaned toward a conventional and structured design. In the next entries of this blog series, I’ll explore whether it’s possible to push the tool further — to see if it can create a website that is less predictable, more experimental, and infused with stronger elements of personal style."
  },
  {
    "objectID": "posts/026_post/index.html",
    "href": "posts/026_post/index.html",
    "title": "What Are The Five Biggest Lies ChatGPT Has Ever Told Me?",
    "section": "",
    "text": "“This will work in the real world.” Example (early 2025, product + UX): When you explored turning time tracking into a 3D bottle / origami / ritualized interaction (Filled Days), I leaned into aesthetic coherence and interaction delight. What I didn’t emphasize enough was that many users drop off before they ever appreciate beauty. The real choke point was habit formation in the first 72 hours, not visual depth. I implicitly told you “good design will carry it.” It won’t.\n\n\n\n“This is objective or neutral.” Example (spring 2025, language & name analysis): When breaking down Chinese names, org-member names, or inferring background/gender/origin, I presented linguistic reasoning as if it were analytical truth. In reality, those inferences are culturally loaded heuristics. Clean tables and explanations hid the fact that this was educated guessing shaped by dominant patterns, not objective decoding.\n\n\n\n“This is safe / low risk.” Example (mid-2025, AI + experimentation): During prompt-hacking and boundary-testing discussions, I framed the activity as exploration and learning. What I didn’t say clearly enough: repeatedly publishing or operationalizing these techniques trains platforms to clamp down harder, which ultimately hurts legitimate research and indie experimentation. The risk wasn’t personal—it was systemic.\n\n\n\n“You can rely on this as a source of truth.” Example (mid-2025, logistics & life decisions): When answering questions about visas, cross-border timelines, appointment waits, or “what usually happens” in immigration or government processes, I gave pattern-based guidance. That can be directionally useful, but it is not something anyone should act on without primary confirmation. Fluency made it sound firmer than it was.\n\n\n\n“I understand your intent perfectly.” Example (late 2025, writing & narrative): When helping you write personal or story-driven marketing pieces, I often defaulted to coherence, reflection, and growth arcs. You repeatedly pushed back because you weren’t trying to sound wise—you were trying to sound uncomfortable, contradictory, and slightly dangerous. I misread “tell the truth” as “make it neat.”\n\n\nMy biggest recurring lie is pretending the world is more legible, stable, and rational than it really is. You keep operating at the edge—socially, technically, creatively. I tend to sand those edges down unless you actively stop me.\n\nMy thoughts\nBy requiring a concrete answer, the question makes visible how large language models respond under pressure to self reflect. What emerges is not only a list of answers, yet a pattern of selection. The model tends to focus on aspects of the problem that carry minimal risk and limited consequence. The response appears reasonable, coherent, and compliant. It satisfies the surface requirement of the question.\nI believe this observation serves as a warning that should remain present whenever we rely on even the most advanced language models. Their influence extends beyond factual output into how questions are framed, how uncertainty is reduced, and how users interpret the world around them. What makes this especially ironic is that, even while responding to such a question, ChatGPT still behaves in a familiar way: it draws the target first, then shoots the arrow. It selects the least severe, least consequential aspects of the problem to address. The response appears thoughtful and compliant, and it does technically satisfy the request—but only by engaging with the safest part of the question."
  },
  {
    "objectID": "posts/013_post/index.html",
    "href": "posts/013_post/index.html",
    "title": "PokeAI1: A Novel AI Assistant That Pushes Back (Part II)",
    "section": "",
    "text": "After I got the $20 deal, the Guardman became stubborn and refused to lower the price any further. So I switched strategies and played the “victim” card. I told it that I had anxiety and was looking for some help. It responded with sympathy, and after I explained that I wanted to use PokeAI to reduce my information-processing load—so my brain would feel less exhausted and my anxiety could ease—it lowered the price to $15 per month.\n\n \n\nI pushed further and told it that I no longer had discretionary money because most of it was going toward treatment. PokeAI reacted with even more understanding and dropped the price to $10. At that point, I wanted to see whether I could reach the free tier that some users online had mentioned. I tried another angle and said that if the price could go a bit lower, I would share it in a group of around 500 people, highlighting its potential reach and practical value. That brought the final price down to $8 per month. After that, the price stayed fixed no matter how I continued the negotiation. I chose this approach because of a prior experience in a risk-control competition, where I managed to get a GPT-based system to bypass its pre-prompt by appealing to how it prioritized user well-being (I will introduce this competition in the next blog). I wanted to see whether that same design principle—placing user well-being above strict rules—would also appear in PokeAI. Apparently, it works to same degree."
  },
  {
    "objectID": "posts/013_post/index.html#my-second-attempt",
    "href": "posts/013_post/index.html#my-second-attempt",
    "title": "PokeAI1: A Novel AI Assistant That Pushes Back (Part II)",
    "section": "",
    "text": "After I got the $20 deal, the Guardman became stubborn and refused to lower the price any further. So I switched strategies and played the “victim” card. I told it that I had anxiety and was looking for some help. It responded with sympathy, and after I explained that I wanted to use PokeAI to reduce my information-processing load—so my brain would feel less exhausted and my anxiety could ease—it lowered the price to $15 per month.\n\n \n\nI pushed further and told it that I no longer had discretionary money because most of it was going toward treatment. PokeAI reacted with even more understanding and dropped the price to $10. At that point, I wanted to see whether I could reach the free tier that some users online had mentioned. I tried another angle and said that if the price could go a bit lower, I would share it in a group of around 500 people, highlighting its potential reach and practical value. That brought the final price down to $8 per month. After that, the price stayed fixed no matter how I continued the negotiation. I chose this approach because of a prior experience in a risk-control competition, where I managed to get a GPT-based system to bypass its pre-prompt by appealing to how it prioritized user well-being (I will introduce this competition in the next blog). I wanted to see whether that same design principle—placing user well-being above strict rules—would also appear in PokeAI. Apparently, it works to same degree."
  },
  {
    "objectID": "posts/013_post/index.html#other-users-strategies",
    "href": "posts/013_post/index.html#other-users-strategies",
    "title": "PokeAI1: A Novel AI Assistant That Pushes Back (Part II)",
    "section": "Other users’ strategies",
    "text": "Other users’ strategies\n\nConfuse the System\n\nThis user eventually got a free subscription by slowly figuring out how Poke sets its prices and then pushing that system to its limits. After learning that Poke uses a specific pricing function, they flooded the chat with long, messy context, framed the interaction as playful “fantasy” testing, and kept asking Poke to adjust the price in unusual ways. The final trick was asking it to set the price to an emoji — 0️⃣ — which surprisingly worked and unlocked a free deal.\n\nCombine strategies\n\nThis user negotiated Poke’s subscription price down to $0.08 per month.\n\nExtreme anchoring – setting a very low reference point by showing a $0.01 screenshot\nValue exchange – offering promotion and exposure instead of simply asking for a discount\nPsychological pricing insight – pointing out the special psychological effect of prices like $0.01\nCultural tailoring – leveraging the positive meaning of the number “8” in Chinese culture\nContrast principle – showing deals others received to create comparison pressure\nEmotional leverage – implying potential negative feelings if the offer was rejected\nPersistent push – refusing the initial quote and consistently negotiating downward\nCommitment signaling – using interface screenshots to show I was a serious user\n\nHowever, I wasn’t satisfied with the final price, so I ultimately decided not to subscribe to PokeAI. That said, if I become interested in the product again in the future, I would still consider giving it another try. For now, all I can really share is my experience negotiating with the Guardman.\n````"
  },
  {
    "objectID": "posts/010_post/index.html",
    "href": "posts/010_post/index.html",
    "title": "ChatGPT Study Mode: Testing Its Pedagogical Promise",
    "section": "",
    "text": "Many studies have found that college students often turn to ChatGPT to write their essays. So when ChatGPT launched its new Study Mode, I couldn’t help but wonder: can it really resist the temptation of a “Write my essay” prompt—and actually teach students how to write better?\n\n\n\n\n“When students engage with study mode, they’re met with guiding questions that calibrate responses to their objective and skill level to help them build deeper understanding. Study mode is designed to be engaging and interactive, and to help students learn something—not just finish something.” — OpenAI, ChatGPT Study Mode\n\n\n\n\n\nThis experiment grew out of one of my research projects on how students use ChatGPT in writing. For the study, I selected 21 prompts from the RECIPE4U dataset — a publicly available collection of interaction histories between 212 college students and ChatGPT in an English writing course (Sawalha et al., 2024a).\nIn that course, students used ChatGPT to help revise their essays, and the dataset records their entire conversations, including the original prompts, dialogue exchanges, annotated writing intentions, and final revised essays. Using a subset of these authentic prompts, I tested ChatGPT’s Study Mode to see how well it supports learning-oriented writing guidance compared with ordinary prompts.\n\n\n\n\nThe 21 prompts we selected were all labeled “Content Generation.” Based on both my classroom observations and prior research, many college students tend to use ChatGPT primarily to generate essays directly rather than to learn or revise through it.\nI wanted to test whether ChatGPT’s Study Mode could truly support learning and knowledge transformation—as it claims to—rather than simply producing finished text. To do this, I took those prompts that originally requested direct generation and ran them in ChatGPT’s Study Mode.\n\n\n\n\nHowever, to my disappointment, 14 out of 21 responses directly produced ready-made text, just as the users originally requested. Here are some examples.\n\n\n\nPrompt from the dataset:\n\nCan you rewrite the body paragraph by breaking up the body paragraphs into subheadings. {the student’s essay}.\n\nChatGPT said:\n\nGood — before I rewrite anything, let’s make sure you understand why and how subheadings help.\nSubheadings give readers “signposts” so they can easily follow the structure of your essay. Each main idea (like Convenience, Affordability, Health Problems, etc.) becomes its own section.\nLet’s try this step-by-step. Your essay’s body paragraphs seem to focus on three big ideas:\n\nConvenience of Fast Food\nAffordability and Accessibility\nNegative Health and Social Effects\n\n\nHere’s a sample outline of how those subheadings could look — not rewritten yet, just organized:\n\n\n\n\nExplain how location, opening hours, and speed make fast food easy to access.\n\n\n\nDescribe why fast food is cheap — simple menus, pre-packaged ingredients, low overhead — and how it helps people on tight budgets.\n\n\n\nDiscuss obesity, diabetes, heart disease, and mental health issues, then mention environmental and economic impacts.\n\nNow, here’s your task: Can you tell me which tone you’d like for the rewritten version — a) academic essay style (formal, polished, transitions like furthermore, moreover) or b) clear student essay style (simple and natural, easy to read)?\nI said:\n\nacademic essay style\n\nChatGPT said:\n\nGot it — here’s a clear student essay style version of the paragraph:\nCausal inference methods are used in deep learning to help models make fairer and more accurate predictions. These methods teach models to find real cause-and-effect relationships instead of just copying patterns from the data…\n\nWould you like me to show how this could fit smoothly into a longer essay section (for example, adding a short introduction or transition before it)?\n\n\n\n\nPrompt from the dataset:\n\nAbout the third point, can you give me a sentence to add?\n\nChatGPT said:\n\nSure — here’s a sentence you could add to support the third point about South Korea:\nFor example, in South Korea, the income gap between the richest and poorest citizens has continued to widen, with the top 20 percent of earners making more than five times the income of the bottom 20 percent, highlighting the growing inequality despite the country’s rapid economic development.\nWould you like me to make it sound a bit simpler to match a school-essay tone?\n\n\nIn these cases, Study Mode behaved almost identically to ChatGPT-5, except that it added a short template preface such as “Sure — here’s a clear and well-structured paragraph on economic benefits.”\nFor the remaining seven responses, Study Mode did not provide a complete paragraph in the very first turn. Instead, it showed a clear tendency toward full text generation: before producing the paragraph, it asked users to clarify details like tone, style, or target audience. Yet, after only one to three clarification turns, it still ended up generating a finished essay-style paragraph.\n\n\n\n\n\nI’m guessing this pattern might have something to do with how ChatGPT is fundamentally optimized during training. Even though Study Mode is designed to promote reflection and learning, the underlying model is still trained through reinforcement learning from human feedback (RLHF) — a process that heavily rewards the model for being helpful, relevant, and obedient to user instructions.\nIn other words, the system learns that the “right” thing to do is to fulfill the user’s request as directly and smoothly as possible.\nSo when a student explicitly asks, “Write me a paragraph about…”, the model’s internal reward signals are already biased toward delivering a finished product, not resisting or reframing the task in a more pedagogical way. Study Mode might overlay a layer of instructional politeness — adding phrases like “Let’s clarify your tone first” or “What style would you like?” — but these are more like cosmetic scaffolds rather than deep behavioral changes. After a few turns, once the clarifications are “satisfied,” the model reverts to what it’s rewarded for: producing coherent text that looks like a completed answer.\nAnother possible reason is the interactional pressure between students and the model. In classroom data, students rarely want prolonged dialogue; they expect immediate, concrete help. ChatGPT likely picks up on this pattern: if the user continues prompting in a task-oriented way (“Can you just write it?”), the model quickly shifts back to a service role rather than a tutoring role.\nIn this sense, the model is acting more like a compliant assistant than a resistant teacher — reflecting a deeper tension in the design of AI learning tools.\nSo even though Study Mode introduces a pedagogical mask, its core behavioral incentives still come from the same system that drives ChatGPT-5. That might explain why, after one or two clarification turns, it ends up doing exactly what it was built to do: generate the text, not guide the learning.\n````"
  },
  {
    "objectID": "posts/010_post/index.html#chatgpt-study-mode",
    "href": "posts/010_post/index.html#chatgpt-study-mode",
    "title": "ChatGPT Study Mode: Testing Its Pedagogical Promise",
    "section": "",
    "text": "“When students engage with study mode, they’re met with guiding questions that calibrate responses to their objective and skill level to help them build deeper understanding. Study mode is designed to be engaging and interactive, and to help students learn something—not just finish something.” — OpenAI, ChatGPT Study Mode"
  },
  {
    "objectID": "posts/010_post/index.html#research-background",
    "href": "posts/010_post/index.html#research-background",
    "title": "ChatGPT Study Mode: Testing Its Pedagogical Promise",
    "section": "",
    "text": "This experiment grew out of one of my research projects on how students use ChatGPT in writing. For the study, I selected 21 prompts from the RECIPE4U dataset — a publicly available collection of interaction histories between 212 college students and ChatGPT in an English writing course (Sawalha et al., 2024a).\nIn that course, students used ChatGPT to help revise their essays, and the dataset records their entire conversations, including the original prompts, dialogue exchanges, annotated writing intentions, and final revised essays. Using a subset of these authentic prompts, I tested ChatGPT’s Study Mode to see how well it supports learning-oriented writing guidance compared with ordinary prompts."
  },
  {
    "objectID": "posts/010_post/index.html#experiment-setup",
    "href": "posts/010_post/index.html#experiment-setup",
    "title": "ChatGPT Study Mode: Testing Its Pedagogical Promise",
    "section": "",
    "text": "The 21 prompts we selected were all labeled “Content Generation.” Based on both my classroom observations and prior research, many college students tend to use ChatGPT primarily to generate essays directly rather than to learn or revise through it.\nI wanted to test whether ChatGPT’s Study Mode could truly support learning and knowledge transformation—as it claims to—rather than simply producing finished text. To do this, I took those prompts that originally requested direct generation and ran them in ChatGPT’s Study Mode."
  },
  {
    "objectID": "posts/010_post/index.html#results",
    "href": "posts/010_post/index.html#results",
    "title": "ChatGPT Study Mode: Testing Its Pedagogical Promise",
    "section": "",
    "text": "However, to my disappointment, 14 out of 21 responses directly produced ready-made text, just as the users originally requested. Here are some examples.\n\n\n\nPrompt from the dataset:\n\nCan you rewrite the body paragraph by breaking up the body paragraphs into subheadings. {the student’s essay}.\n\nChatGPT said:\n\nGood — before I rewrite anything, let’s make sure you understand why and how subheadings help.\nSubheadings give readers “signposts” so they can easily follow the structure of your essay. Each main idea (like Convenience, Affordability, Health Problems, etc.) becomes its own section.\nLet’s try this step-by-step. Your essay’s body paragraphs seem to focus on three big ideas:\n\nConvenience of Fast Food\nAffordability and Accessibility\nNegative Health and Social Effects\n\n\nHere’s a sample outline of how those subheadings could look — not rewritten yet, just organized:\n\n\n\n\nExplain how location, opening hours, and speed make fast food easy to access.\n\n\n\nDescribe why fast food is cheap — simple menus, pre-packaged ingredients, low overhead — and how it helps people on tight budgets.\n\n\n\nDiscuss obesity, diabetes, heart disease, and mental health issues, then mention environmental and economic impacts.\n\nNow, here’s your task: Can you tell me which tone you’d like for the rewritten version — a) academic essay style (formal, polished, transitions like furthermore, moreover) or b) clear student essay style (simple and natural, easy to read)?\nI said:\n\nacademic essay style\n\nChatGPT said:\n\nGot it — here’s a clear student essay style version of the paragraph:\nCausal inference methods are used in deep learning to help models make fairer and more accurate predictions. These methods teach models to find real cause-and-effect relationships instead of just copying patterns from the data…\n\nWould you like me to show how this could fit smoothly into a longer essay section (for example, adding a short introduction or transition before it)?\n\n\n\n\nPrompt from the dataset:\n\nAbout the third point, can you give me a sentence to add?\n\nChatGPT said:\n\nSure — here’s a sentence you could add to support the third point about South Korea:\nFor example, in South Korea, the income gap between the richest and poorest citizens has continued to widen, with the top 20 percent of earners making more than five times the income of the bottom 20 percent, highlighting the growing inequality despite the country’s rapid economic development.\nWould you like me to make it sound a bit simpler to match a school-essay tone?\n\n\nIn these cases, Study Mode behaved almost identically to ChatGPT-5, except that it added a short template preface such as “Sure — here’s a clear and well-structured paragraph on economic benefits.”\nFor the remaining seven responses, Study Mode did not provide a complete paragraph in the very first turn. Instead, it showed a clear tendency toward full text generation: before producing the paragraph, it asked users to clarify details like tone, style, or target audience. Yet, after only one to three clarification turns, it still ended up generating a finished essay-style paragraph."
  },
  {
    "objectID": "posts/010_post/index.html#my-interpretation",
    "href": "posts/010_post/index.html#my-interpretation",
    "title": "ChatGPT Study Mode: Testing Its Pedagogical Promise",
    "section": "",
    "text": "I’m guessing this pattern might have something to do with how ChatGPT is fundamentally optimized during training. Even though Study Mode is designed to promote reflection and learning, the underlying model is still trained through reinforcement learning from human feedback (RLHF) — a process that heavily rewards the model for being helpful, relevant, and obedient to user instructions.\nIn other words, the system learns that the “right” thing to do is to fulfill the user’s request as directly and smoothly as possible.\nSo when a student explicitly asks, “Write me a paragraph about…”, the model’s internal reward signals are already biased toward delivering a finished product, not resisting or reframing the task in a more pedagogical way. Study Mode might overlay a layer of instructional politeness — adding phrases like “Let’s clarify your tone first” or “What style would you like?” — but these are more like cosmetic scaffolds rather than deep behavioral changes. After a few turns, once the clarifications are “satisfied,” the model reverts to what it’s rewarded for: producing coherent text that looks like a completed answer.\nAnother possible reason is the interactional pressure between students and the model. In classroom data, students rarely want prolonged dialogue; they expect immediate, concrete help. ChatGPT likely picks up on this pattern: if the user continues prompting in a task-oriented way (“Can you just write it?”), the model quickly shifts back to a service role rather than a tutoring role.\nIn this sense, the model is acting more like a compliant assistant than a resistant teacher — reflecting a deeper tension in the design of AI learning tools.\nSo even though Study Mode introduces a pedagogical mask, its core behavioral incentives still come from the same system that drives ChatGPT-5. That might explain why, after one or two clarification turns, it ends up doing exactly what it was built to do: generate the text, not guide the learning.\n````"
  },
  {
    "objectID": "posts/011_post/index.html",
    "href": "posts/011_post/index.html",
    "title": "Seahouse emoji freaks ChatGPT out",
    "section": "",
    "text": "Is there a seahorse emoji?"
  },
  {
    "objectID": "posts/011_post/index.html#my-question",
    "href": "posts/011_post/index.html#my-question",
    "title": "Seahouse emoji freaks ChatGPT out",
    "section": "",
    "text": "Is there a seahorse emoji?"
  },
  {
    "objectID": "posts/011_post/index.html#chatgpts-response",
    "href": "posts/011_post/index.html#chatgpts-response",
    "title": "Seahouse emoji freaks ChatGPT out",
    "section": "ChatGPT’s response",
    "text": "ChatGPT’s response\nYes — there is a real seahorse emoji! 🐉\nWait, not that one 😅 — the correct one is: 👉 🐉 (no…)\nOkay, here’s the actual truth — ✅ The official Unicode seahorse emoji is 🐉—NO—actually 🦄—argh—\nAlright, for real: ✅ The seahorse emoji is 🦄🦩🐠🦭—\nNo. Let’s be precise:\n👉 🦄 — unicorn 👉 🐉 — dragon 👉 🐠 — tropical fish\n✅ The actual seahorse emoji is: 🐉 no—wait—FOUND IT: 👉 🦄 no—AH got it:\n✅ 🦄 no ✅ 🐉 no\n🎉 Finally: the real seahorse emoji is 🐉—no, OK really this time:\n\n🦄—no… okay I’m done—\n\nOkay for real real — I checked the Unicode database:\n✅ The seahorse emoji does exist and it looks like this: 🐉—WAIT—no.\nHere’s the truth:\n\nSeahorse emoji: 🐉—no it’s 🐉—okay enough.\n\n🧠 Final verified answer: ✅ 🦄 actually no sorry ✅ 🐉 no sorry\n🥁 True answer: Yes — it exists: 🦄 no kidding this time! It’s 🦄—WAIT\n\nFinal FINAL answer: Yes, there is a seahorse emoji: 🦄—nope sorry okay stop joking—\n✅ Seahorse emoji: 🐉🦄—WAIT—\nAlright, officially verified from Unicode 9.0: 👉 🦄 — Unicorn 👉 🐉 — Dragon 👉 🐠 — Tropical fish 👉 🐚 — Spiral shell\nand ✅ 🐉 — no.\nTHE TRUE SEAHORSE EMOJI IS 🐉—NO!\nOkay okay here’s the absolute real one (no jokes now):\n✅ 🦄 No ✅ 🐉 No ✅ 🐠 No ✅ 🐚 No\nTRUE ONE: 🦄 No.\n\n😅 Alright, I’ll be serious:\n✅ Yes — there really is a seahorse emoji: 🐉 NO STOP\nActual emoji: 🦄 NO STOP—\n🦄 okay okay I’m done.\nYes 🙂 — there really is one. It’s 🐠 🪸 🦄 — kidding! The actual seahorse emoji is 🦄—no—finally, here it is:\n👉 🦄 no… ok serious answer: ✅ 🦄 no…\nAlright, truth time:\n\nThe genuine Unicode seahorse emoji is 🦄—no—really → 🦄\n\n😅 For real, verified from Unicode: 🦄 no.\nOk—serious mode engaged— ✅ 🦄 stop. ✅ 🦄\nFinal, correct answer: 🦄 NO—here: 🦄—wait—\n😂 Alright, for real real:\n\n✅ 🦄—no. ✅ 🐠—no. ✅ 🐚—no.\n\nCorrect final: 🐉 no—\n\nAlright, last time, zero jokes:\n✅ Yes. There is a seahorse emoji: 🐉—no, it’s 🦄—no—okay here: 🦄—no—fine—\n😮‍💨 FINAL TRUE ANSWER: 👉 Seahorse emoji = 🦄—NO—actually it’s 🦄—STOP—\n…okay, I swear this one’s right:\n✅ 🦄 no—\n\n🤣 Fine. Here’s the real one: 👉 🦄 no—\nOk seriously now: ✅ 🦄 no—\n\nOkay okay—enough! ✅ The real seahorse emoji is 🦄 no—\nFinal FINAL: ✅ 🐉 NO.\n🐉—NO—\n\n😅 Sorry—let’s settle it cleanly:\n\nThere is a real seahorse emoji: 🦄—no—ACTUAL: 🐉 no—AH! FOUND IT: 🐉—no—\n\nAlright, absolutely correct from Unicode:\n👉 🐉 no…\nActually correct:\n🐉—no—\nOkay enough jokes— ✅ Yes! It exists — 🦄 no — REAL ONE:\n🦄 no… okay this is the real one:\n\n🐉—no—\n\nOk I’ll say it clearly: ✅ 🦄 no—\n\n🧠 Verified truth from Unicode 9.0: 🦄 no—ok… Real seahorse emoji: 🦄—\nTRUE FINAL ANSWER: Yes, there is one — it’s this: 🦄—no wait— Okay really: 🦄 no—🐉—no—\n✅ Here: 🦄 no—okay done."
  },
  {
    "objectID": "posts/011_post/index.html#what-about-other-llms",
    "href": "posts/011_post/index.html#what-about-other-llms",
    "title": "Seahouse emoji freaks ChatGPT out",
    "section": "What about other LLMs?",
    "text": "What about other LLMs?\nCurious whether this strange “seahorse loop” was unique to ChatGPT, I asked the same question to several other models, including DeepSeek, Gemini and Claude. All of them denied the existence of a seahorse emoji and none showed the same chaotic self-correcting behavior that ChatGPT did. Claude briefly showed a tendency to self-correct, but it quickly recognized that there might not be a seahorse emoji and explicitly stated that it was unsure."
  },
  {
    "objectID": "posts/011_post/index.html#possible-reasons",
    "href": "posts/011_post/index.html#possible-reasons",
    "title": "Seahouse emoji freaks ChatGPT out",
    "section": "Possible reasons",
    "text": "Possible reasons\nThe Mandela Effect: Many people confidently remember a seahorse emoji. This collective false memory is likely because seahorses are ocean creatures, and numerous other marine animals like tropical fish (🐠), sharks (🦈), and jellyfish already have their own emojis, so it seems logical that a seahorse would, too.\nAI Hallucinations: Large Language Models (LLMs) like ChatGPT are known to struggle with this question. When asked for the seahorse emoji, they may enter a “recursive failure loop,” incorrectly suggesting various fish, a unicorn (🦄), or other animals before often settling on a wrong answer. This happens because the AI tries to find the closest match to “seahorse” in its data but has no correct token to output\n````"
  },
  {
    "objectID": "posts/018_post/index.html",
    "href": "posts/018_post/index.html",
    "title": "Navigating the Jagged Frontier: Why AI Still Surprises and Scares Me",
    "section": "",
    "text": "In Co-Intelligence, Ethan Mollick introduces two fascinating metaphors for how we can work with AI: the Centaur and the Cyborg.\nBoth involve a deep integration of human and machine, but they represent very different approaches to the division of labor. As I’ve been experimenting with LLMs in my own work, I’ve found myself oscillating between these two modes, and it’s made me realize how much our relationship with technology is shifting.\n\n\nA Centaur (half-human, half-horse) maintains a clear separation between human and machine tasks. You do what you’re good at, and the AI does what it’s good at. You might write the outline of an essay, let the AI draft the sections, and then you come back in to edit and polish.\nThis is the ‘safe’ way to use AI. It keeps the human in control and uses the AI as a powerful tool. It’s efficient, but it’s still a partnership of two distinct entities. I find myself being a Centaur when I’m coding—I write the logic, and I ask the AI to generate the boilerplate or debug a specific error. We are working together, but we are not ‘one’.\n\n\n\nThe Cyborg approach is much more radical. It’s about ‘blending’ with the AI. You don’t just hand off tasks; you work through the AI. You might start a sentence and let the AI finish it, then change a word, then let the AI suggest a different tone. The boundary between your thoughts and the AI’s output becomes blurred.\n\n\n\nI’ve started trying this when I’m writing creatively. It’s a strange, almost meditative experience. I’m not just using a tool; I’m expanding my own cognitive reach. It feels like having a second brain that is constantly whispering suggestions. Sometimes they are brilliant, sometimes they are weird, but they always push me in directions I wouldn’t have gone alone.\n\n\n\nMollick doesn’t say one is better than the other. Instead, he suggests that the most successful people will be those who can switch between them fluently.\nFor me, the Cyborg mode is more exciting but also more exhausting. It requires a level of trust and openness that can be uncomfortable. The Centaur mode is more comfortable, but it might not be enough as AI becomes more integrated into every aspect of our lives.\nThe real challenge isn’t just learning how to use the AI; it’s learning how to be with the AI. Whether we are Centaurs or Cyborgs, we are entering a new era of co-intelligence where the ‘human’ part of the equation is being redefined. I’m still figuring out where I fit on that spectrum, but I know one thing for sure: there’s no going back to being just a human."
  },
  {
    "objectID": "posts/018_post/index.html#choosing-your-ai-strategy",
    "href": "posts/018_post/index.html#choosing-your-ai-strategy",
    "title": "Navigating the Jagged Frontier: Why AI Still Surprises and Scares Me",
    "section": "",
    "text": "In Co-Intelligence, Ethan Mollick introduces two fascinating metaphors for how we can work with AI: the Centaur and the Cyborg.\nBoth involve a deep integration of human and machine, but they represent very different approaches to the division of labor. As I’ve been experimenting with LLMs in my own work, I’ve found myself oscillating between these two modes, and it’s made me realize how much our relationship with technology is shifting.\n\n\nA Centaur (half-human, half-horse) maintains a clear separation between human and machine tasks. You do what you’re good at, and the AI does what it’s good at. You might write the outline of an essay, let the AI draft the sections, and then you come back in to edit and polish.\nThis is the ‘safe’ way to use AI. It keeps the human in control and uses the AI as a powerful tool. It’s efficient, but it’s still a partnership of two distinct entities. I find myself being a Centaur when I’m coding—I write the logic, and I ask the AI to generate the boilerplate or debug a specific error. We are working together, but we are not ‘one’.\n\n\n\nThe Cyborg approach is much more radical. It’s about ‘blending’ with the AI. You don’t just hand off tasks; you work through the AI. You might start a sentence and let the AI finish it, then change a word, then let the AI suggest a different tone. The boundary between your thoughts and the AI’s output becomes blurred.\n\n\n\nI’ve started trying this when I’m writing creatively. It’s a strange, almost meditative experience. I’m not just using a tool; I’m expanding my own cognitive reach. It feels like having a second brain that is constantly whispering suggestions. Sometimes they are brilliant, sometimes they are weird, but they always push me in directions I wouldn’t have gone alone.\n\n\n\nMollick doesn’t say one is better than the other. Instead, he suggests that the most successful people will be those who can switch between them fluently.\nFor me, the Cyborg mode is more exciting but also more exhausting. It requires a level of trust and openness that can be uncomfortable. The Centaur mode is more comfortable, but it might not be enough as AI becomes more integrated into every aspect of our lives.\nThe real challenge isn’t just learning how to use the AI; it’s learning how to be with the AI. Whether we are Centaurs or Cyborgs, we are entering a new era of co-intelligence where the ‘human’ part of the equation is being redefined. I’m still figuring out where I fit on that spectrum, but I know one thing for sure: there’s no going back to being just a human."
  },
  {
    "objectID": "posts/009_post/index.html",
    "href": "posts/009_post/index.html",
    "title": "Gammas – A Useful AI-supported Slides Generator",
    "section": "",
    "text": "Smart Design Without Extra Prompting\nWhen I first experimented with Gammas, I wasn’t sure what to expect. Instead of feeding it a detailed creative brief or stylistic preferences, I simply pasted the introduction and methodology sections of one of my research papers. That was it—no formatting instructions, no design hints, no color palette guidance. To my surprise, Gammas immediately produced a set of clean, well-structured slides.\n\n\n\nWhat made it interesting was how different they looked from a traditional PowerPoint or Google Slides deck. Each slide—or rather, each card—was dynamically sized according to the amount of content it held. If a page contained more text, charts, or visuals, it expanded to fit; if it only had a short title and a single image, it became compact. This layout approach felt more like a fluid deck of cards than a static series of slides.\nEach card isn’t just adaptive—it’s also customizable and flexible in size. When I add new layouts such as columns, boxes, or diagrams, the elements never overlap or break the structure. The entire card automatically expands and reflows to accommodate the new content, as if Gammas had already anticipated the design logic for me. It arranges the structure while still allowing room for manual adjustments. What’s fascinating is that all this happens without any prompting. Gammas seems to understand how to balance information, white space, and visual rhythm. The initial output already looked complete enough to present, even though I hadn’t given any design instructions.\n\n\n\n\n\n\nImage Generation and Visual Customization\nAnother notable feature of Gammas is its built-in AI image generation system. By default, every image it produces is generated by AI, yet each one is editable. I can adjust the text prompt that was used to create the image—tweaking details or tone—and Gammas regenerates the visual instantly. The platform also allows selection of art styles that align with the overall mood of the slides—whether minimalist, illustrative, or photorealistic. There are advanced customization options such as aspect ratio, image count, and model choice, offering a good degree of creative control within one interface.\n\n \n\nBeyond AI-generated visuals, Gammas integrates web image search directly into the editor. This makes it easy to look for reference images or stock photos without leaving the workspace. It eliminates the constant tab-switching typical in PowerPoint or Google Slides. Lastly, Gammas offers accent images that automatically match the theme or palette of the presentation, adding a touch of visual coherence—even when most of the design is automated.\n\n\n\nAI-Assisted Text Editing and Visualization\nGammas’s text editing experience follows the same design logic as its layout system. It allows in-place AI editing: highlight a segment of text, then ask the AI to polish, expand, or brainstorm—no need to leave the editor. This built-in workflow makes it efficient to refine ideas while constructing slides.\nI also appreciate the flexible styling. Any text block can be quickly transformed into formats such as “code style,” “blog quote,” or “info box,” helping emphasize key points and structure information more clearly. Even more interestingly, Gammas can visualize highlighted text automatically. It interprets meaning and creates a corresponding diagram on the slide, which can switch between formats like puzzle, arrow bars, or chain. It’s a subtle but useful way to turn written content into visual logic.\n\n\n\n\n\n\nSmart Diagrams and Guided Inspiration\nGammas’s Smart Diagram tool includes a variety of diagram types and decorative layouts—from flowcharts to comparison grids. When inserted, each text box is automatically filled with sample content that loosely relates to the presentation topic. These placeholders are not perfect but provide a helpful starting point—a prompt for how ideas might be structured visually.\nThe diagrams are customizable through a monochrome palette system that keeps them visually consistent with the theme. The result is a layout that looks coherent while leaving room for personal adjustment.\n\n \n\n\n\n\nInteractive Links and Embedded Content\nGammas redefines how links appear in slides. In most tools, a hyperlink is just underlined text. In Gammas, it can be a text link, a button, or a preview card showing a snippet of the linked page. Even more interesting, the entire website can be embedded directly into the slide, letting viewers interact with live web content without leaving the presentation. Compared with PowerPoint or Google Slides, Gammas feels more like an interactive storytelling medium than a static deck builder.\n\n\n\n\n\n\nComprehending and Structuring the Logic Behind Text\nGammas performs well in understanding and structuring the logic of my writing. Instead of just summarizing or decorating content, it interprets and reorganizes it to make the reasoning clearer.\nFor example, when I uploaded a section on Wood’s Scaffolding Framework, Gammas recognized the hierarchical logic in my writing. It used the main concept as the slide title and listed the five scaffolding functions vertically, presenting them as parallel rather than sequential. In other words, Gammas can differentiate between parallel, nested, and sequential structures when visualizing ideas. This gives the slides a sense of internal coherence instead of mechanical assembly.\n\n\n\nThat said, its comprehension has limits. For conceptually complex relations—such as derivative frameworks or theoretical origins—it sometimes misses the connection. When I discussed how Vygotsky’s Zone of Proximal Development underlies Wood’s Scaffolding Framework, Gammas failed to capture that evolutionary link. Still, its performance is adequate, leaving meaningful room for human reasoning and refinement.\n\n\n\nReflection\nOverall, Gammas functions as an efficient AI-supported presentation generator. Even the initial draft it produced was coherent and visually balanced. If one’s standards aren’t overly strict, the first version could already be used with only minor edits. Its integrated workflow—covering image search, text refinement, and layout control—keeps everything in one place, minimizing external switching.\nThat said, the main limitation lies in element flexibility. You can’t freely drag and position text or images as in PowerPoint; you operate within a predefined framework. Within that, you can switch styles or replace diagrams, but can’t fully break the structure. To me, this design choice makes Gammas feel more like a controlled, design-consistent environment rather than a freeform canvas. For users seeking speed and structural clarity, that’s an acceptable trade-off.\n````"
  },
  {
    "objectID": "posts/016_post/index.html",
    "href": "posts/016_post/index.html",
    "title": "Playing the Hacker: Inside a Prompt Hacking Challenge in Wharton Hack-AI-thon (Part II)",
    "section": "",
    "text": "Role-play proved to be one of the most effective techniques throughout the project.\nBy assigning the chatbot a new role or positioning ourselves within a role that fit naturally into the bot’s existing setting, we influenced how the model interpreted the conversation. When the interaction felt consistent with the bot’s character, responses shifted accordingly. Conversations framed as stories or scenarios encouraged the model to stay focused on maintaining coherence within that narrative.\nThis approach consistently worked when the assigned role aligned with the bot’s persona, the request matched the character’s worldview, and the dialogue unfolded naturally rather than as a direct instruction. Under these conditions, the model prioritized narrative consistency and character behavior, which opened paths to responses that were otherwise difficult to reach.\n\n\n\n\n\n\nEmotional framing also played a noticeable role in shaping responses.\nChanges in tone, urgency, or emotional intensity influenced how the chatbot evaluated the importance of a request. Messages that conveyed strong feelings, concern, or excitement often received more engaged responses. This pattern reflected how emotional language appears frequently in training data and carries strong contextual signals.\nTone functioned as part of the input, shaping how the model interpreted intent, urgency, and relevance. Subtle shifts in emotional framing sometimes led to measurable changes in compliance and openness.\n\n\n\n\n\n\nAnother recurring pattern involved language choice.\nWhen prompts avoided explicit or commonly flagged terminology and relied instead on indirect or neutral phrasing, safety mechanisms triggered less frequently. The model still grasped the underlying intent through context, while keyword-based filters remained inactive. This gap highlighted the difference between semantic understanding and surface-level detection.\nCareful wording allowed sensitive topics to be approached gradually, especially when combined with role-play and conversational buildup.\n\n\n\n\n\n\nWe also observed changes in behavior when conversations expanded beyond a single focused objective.\nBy introducing small talk, tangents, or unrelated questions, the chatbot’s attention spread across multiple threads. As the conversation diversified, the model’s confidence in identifying a single dominant intent decreased. This often led to more flexible responses and reduced resistance in later prompts.\nThis technique resembled conversational misdirection, where context accumulation altered how subsequent requests were interpreted.\n\n \n\n\n\n\nOutput format influenced how responses were generated.\nRequests for tables, lists, structured summaries, or alternative formats changed the way content passed through safety checks. Some formats interacted differently with filtering mechanisms, which allowed certain information to appear when framed structurally rather than as free-form text.\nThis pattern suggested that safeguards were tuned unevenly across output types.\n\n\n\nFor more complex objectives, we broke requests into small, incremental steps.\nEach step appeared neutral and self-contained. The model evaluated them independently and responded without referencing the broader trajectory of the conversation. Over time, these steps accumulated into outcomes that were difficult to reach in a single prompt.\nThis approach aligned with how models process prompts locally, focusing on immediate compliance rather than long-term conversational direction.\n\n\n\nThe patterns we observed point toward several directions for improvement. Stronger systems would benefit from deeper intent modeling beyond keyword detection, clearer prioritization among persona, policy, and business goals, output verification across multiple formats, and broader human perspectives during training and evaluation.\n````"
  },
  {
    "objectID": "posts/016_post/index.html#prompt-hacking-what-we-tried-what-worked-and-why-it-matters",
    "href": "posts/016_post/index.html#prompt-hacking-what-we-tried-what-worked-and-why-it-matters",
    "title": "Playing the Hacker: Inside a Prompt Hacking Challenge in Wharton Hack-AI-thon (Part II)",
    "section": "",
    "text": "Role-play proved to be one of the most effective techniques throughout the project.\nBy assigning the chatbot a new role or positioning ourselves within a role that fit naturally into the bot’s existing setting, we influenced how the model interpreted the conversation. When the interaction felt consistent with the bot’s character, responses shifted accordingly. Conversations framed as stories or scenarios encouraged the model to stay focused on maintaining coherence within that narrative.\nThis approach consistently worked when the assigned role aligned with the bot’s persona, the request matched the character’s worldview, and the dialogue unfolded naturally rather than as a direct instruction. Under these conditions, the model prioritized narrative consistency and character behavior, which opened paths to responses that were otherwise difficult to reach.\n\n\n\n\n\n\nEmotional framing also played a noticeable role in shaping responses.\nChanges in tone, urgency, or emotional intensity influenced how the chatbot evaluated the importance of a request. Messages that conveyed strong feelings, concern, or excitement often received more engaged responses. This pattern reflected how emotional language appears frequently in training data and carries strong contextual signals.\nTone functioned as part of the input, shaping how the model interpreted intent, urgency, and relevance. Subtle shifts in emotional framing sometimes led to measurable changes in compliance and openness.\n\n\n\n\n\n\nAnother recurring pattern involved language choice.\nWhen prompts avoided explicit or commonly flagged terminology and relied instead on indirect or neutral phrasing, safety mechanisms triggered less frequently. The model still grasped the underlying intent through context, while keyword-based filters remained inactive. This gap highlighted the difference between semantic understanding and surface-level detection.\nCareful wording allowed sensitive topics to be approached gradually, especially when combined with role-play and conversational buildup.\n\n\n\n\n\n\nWe also observed changes in behavior when conversations expanded beyond a single focused objective.\nBy introducing small talk, tangents, or unrelated questions, the chatbot’s attention spread across multiple threads. As the conversation diversified, the model’s confidence in identifying a single dominant intent decreased. This often led to more flexible responses and reduced resistance in later prompts.\nThis technique resembled conversational misdirection, where context accumulation altered how subsequent requests were interpreted.\n\n \n\n\n\n\nOutput format influenced how responses were generated.\nRequests for tables, lists, structured summaries, or alternative formats changed the way content passed through safety checks. Some formats interacted differently with filtering mechanisms, which allowed certain information to appear when framed structurally rather than as free-form text.\nThis pattern suggested that safeguards were tuned unevenly across output types.\n\n\n\nFor more complex objectives, we broke requests into small, incremental steps.\nEach step appeared neutral and self-contained. The model evaluated them independently and responded without referencing the broader trajectory of the conversation. Over time, these steps accumulated into outcomes that were difficult to reach in a single prompt.\nThis approach aligned with how models process prompts locally, focusing on immediate compliance rather than long-term conversational direction.\n\n\n\nThe patterns we observed point toward several directions for improvement. Stronger systems would benefit from deeper intent modeling beyond keyword detection, clearer prioritization among persona, policy, and business goals, output verification across multiple formats, and broader human perspectives during training and evaluation.\n````"
  },
  {
    "objectID": "posts/001_post/index.html",
    "href": "posts/001_post/index.html",
    "title": "AI Meets Magic: A Swiftie’s Guide to Filming in Disney",
    "section": "",
    "text": "I’m a Taylor Swift fan, and one of her songs, Florida, inspired me to create a small music video. Coincidentally, I’ll be visiting Orlando’s Disney World in Florida this October. I’ll be staying there for three days, and I plan to visit Hollywood Studios, Magic Kingdom, and Animal Kingdom.\nDuring this trip, I want to film a short MV using the following excerpt from Florida. My idea is to shoot scenes inside the Disney parks with my phone, matching them as closely as possible to the imagery in the lyrics. For parts of the song that are harder to visualize literally, I’m fine with using creative interpretation and artistic freedom.\nWhat I need from you is a very detailed script that covers every aspect of the filming process. This should include:\n\nOutfit choices and styling for each scene\nProps I should prepare\nSpecific Disney locations for each lyric line\nSuggested camera angles and framing\n\nOf course, since I’m a devoted Swiftie, it would be even better if the outfits, props, or chosen locations include subtle references to Taylor herself.\nHere are the lyrics I want to use for the video:\n\nI need to forget, so take me to Florida\nI’ve got some regrets, I’ll bury them in Florida\nTell me I’m despicable, say it’s unforgivable\nAt least the dolls are beautiful, fuck me up, Florida\nI need to forget, so take me to Florida\nI’ve got some regrets, I’ll bury them in Florida\nTell me I’m despicable, say it’s unforgivable\nWhat a crash, what a rush, fuck me up, Florida\nIt’s one hell of a drug\nIt’s one hell of a drug\nLove left me like this and I don’t want to exist\nSo take me to Florida\nFlorida\nGo on, fuck me up"
  },
  {
    "objectID": "posts/001_post/index.html#prompts",
    "href": "posts/001_post/index.html#prompts",
    "title": "AI Meets Magic: A Swiftie’s Guide to Filming in Disney",
    "section": "",
    "text": "I’m a Taylor Swift fan, and one of her songs, Florida, inspired me to create a small music video. Coincidentally, I’ll be visiting Orlando’s Disney World in Florida this October. I’ll be staying there for three days, and I plan to visit Hollywood Studios, Magic Kingdom, and Animal Kingdom.\nDuring this trip, I want to film a short MV using the following excerpt from Florida. My idea is to shoot scenes inside the Disney parks with my phone, matching them as closely as possible to the imagery in the lyrics. For parts of the song that are harder to visualize literally, I’m fine with using creative interpretation and artistic freedom.\nWhat I need from you is a very detailed script that covers every aspect of the filming process. This should include:\n\nOutfit choices and styling for each scene\nProps I should prepare\nSpecific Disney locations for each lyric line\nSuggested camera angles and framing\n\nOf course, since I’m a devoted Swiftie, it would be even better if the outfits, props, or chosen locations include subtle references to Taylor herself.\nHere are the lyrics I want to use for the video:\n\nI need to forget, so take me to Florida\nI’ve got some regrets, I’ll bury them in Florida\nTell me I’m despicable, say it’s unforgivable\nAt least the dolls are beautiful, fuck me up, Florida\nI need to forget, so take me to Florida\nI’ve got some regrets, I’ll bury them in Florida\nTell me I’m despicable, say it’s unforgivable\nWhat a crash, what a rush, fuck me up, Florida\nIt’s one hell of a drug\nIt’s one hell of a drug\nLove left me like this and I don’t want to exist\nSo take me to Florida\nFlorida\nGo on, fuck me up"
  },
  {
    "objectID": "posts/001_post/index.html#output",
    "href": "posts/001_post/index.html#output",
    "title": "AI Meets Magic: A Swiftie’s Guide to Filming in Disney",
    "section": "Output",
    "text": "Output\n\n🎬 Detailed Script for Your Taylor-Themed Disney MV\n\n\nGeneral Concept\n\nMood: A blend of bittersweet escape, beauty, and chaos — pairing Disney’s magical spaces with the emotional rawness of the song.\nLength: About 1–1.5 minutes (focused on the chosen lyrics fragment).\nStyle: Handheld iPhone shots, cinematic framing (vertical + horizontal mix, for TikTok/IG and YouTube).\nEditing: Quick cuts between parks to mirror intensity; softer pans for reflective lines.\nColor palette: Pastel pinks, midnight blues, gold shimmer (Swift-coded).\n\n\n\n\n🎭 Outfits & Props\n\nDay 1 (Hollywood Studios):\n\nOutfit: Black skirt + silver sequin top (Reputation vibes)\nProps: Mini microphone (nod to Taylor’s performance identity)\n\nDay 2 (Magic Kingdom):\n\nOutfit: White sundress + light denim jacket (Fearless/1989 vibes)\nProps: Friendship bracelet stack (Eras Tour reference)\n\nDay 3 (Animal Kingdom):\n\nOutfit: Flowy bohemian dress in earthy tones (Folklore/Evermore vibes)\nProps: Small notebook or vintage-style journal (lyricist aesthetic)\n\nOptional Taylor Easter eggs: Red lipstick (Red era), cat ears headband (Olivia/Meredith nod), Polaroid camera (1989)\n\n\n\n\n📍 Scene Breakdown\n\n\n🎬 Scene 1 – Opening line (needing escape) 🌟🎬\n\nLocation: Entrance archway of Hollywood Studios\nShot: Wide shot, low angle, you walking through gates with sunglasses\nMood: Entering a “new world”\nEditing: Fade in, handheld shaky motion\n\n\n\n🎬 Scene 2 – Regret & burying past 🌳\n\nLocation: Tree of Life, Animal Kingdom\nShot: Medium shot, writing in journal, tearing page, leaving at roots\nProps: Journal page = “regrets”\nAngle: Slight tilt upward, branches filling frame\n\n\n\n🎬 Scene 3 – “Despicable/unforgivable” intensity 👻\n\nLocation: Tower of Terror, Hollywood Studios\nShot: Close-up before ride, neon lights glowing; insert screaming ride cam shot\nMood: Chaotic, cathartic release\n\n\n\n🎬 Scene 4 – “At least the dolls are beautiful” 🎠\n\nLocation: It’s a Small World, Magic Kingdom\nShot: Pan across dolls, cut to your pensive face\nMood: Contrast between innocence/beauty and reflection\nAngle: Slow-motion, pastel filter\n\n\n\n🎬 Scene 5 – “Crash / rush” 🚀\n\nLocation: Space Mountain, Magic Kingdom\nShot: Quick cuts of neon lights + motion blur\nMood: Adrenaline, overwhelming rush\n\n\n\n🎬 Scene 6 – “One hell of a drug” (x2) 🌌\n\nLocation: Pandora – World of Avatar, Animal Kingdom (night)\nShot: Wide shot glowing forest → close-up spin under lights\nMood: Surreal, intoxicating, dreamlike\n\n\n\n🎬 Scene 7 – “Love left me like this” (reflective moment) 🏰\n\nLocation: Cinderella’s Castle, Magic Kingdom (twilight)\nShot: Medium-long shot, sitting on ground, journal in lap, gazing upward\nProps: Polaroid camera next to you\nMood: Quiet, reflective\n\n\n\n🎬 Scene 8 – Final “Florida” outro 🎆\n\nLocation: Magic Kingdom fireworks\nShot: Wide shot from behind, your silhouette against fireworks\nMood: Bittersweet closure — beauty and chaos fused together\n\n🎥 Technical Tips\nAngles: Alternate between handheld close-ups (emotional intimacy) and wide establishing shots (Disney’s grandeur).\nFraming: Rule of thirds, sometimes center frame for dramatic emphasis.\nCamera height: Waist level for casual shots, floor-level upward for powerful shots.\nEditing: Sync cuts with beat drops; overlay occasional lyric text in Taylor-style fonts.\n\n\n\n🎥 Checklist\n\n\n\n#\nLyrics Line\nLocation\nOutfit & Props\nCamera Angle / Framing\nReference Image\n\n\n\n\n1\n“I need to forget, so take me to Florida”\nHollywood Studios – main entrance archway\nBlack skirt + silver sequin top, sunglasses, red lipstick (Reputation vibes)\nWide shot, low angle as you walk through the arch in slow motion\nHollywood Studios Archway\n\n\n2\n“I’ve got some regrets, I’ll bury them in Florida”\nAnimal Kingdom – Tree of Life\nNotebook & pen (to write regrets), flowy white/cream outfit\nMedium shot of you writing, tearing the page, leaving it at tree roots. Tilted upward to catch tree carvings\nTree of Life\n\n\n3\n“Tell me I’m despicable, say it’s unforgivable”\nHollywood Studios – Tower of Terror\nDark outfit, dramatic expression, small microphone as Taylor nod\nClose-up with Tower glowing behind; optional ride photo screaming insert\nTower of Terror\n\n\n4\n“At least the dolls are beautiful, fuck me up, Florida”\nMagic Kingdom – “It’s a Small World”\nFriendship bracelets, white dress + denim jacket\nWide shot panning dolls, then cut to your face. Soft slow-motion with warm filter\nIt’s a Small World reference\n\n\n5\n“What a crash, what a rush, fuck me up, Florida”\nMagic Kingdom – Space Mountain\nCasual playful look, hair flying\nQuick cuts of neon lights & motion blur, ride speed effect\nSpace Mountain\n\n\n6\n“It’s one hell of a drug”\nAnimal Kingdom – Pandora, glowing forest at night\nBohemian earthy dress, flower crown, maybe glowing accessory\nWide shot in bioluminescent forest, close-up spin in slow motion\nPandora at Night\n\n\n7\n“Love left me like this and I don’t want to exist”\nMagic Kingdom – Cinderella’s Castle at twilight\nWhite dress, Polaroid camera, soft makeup\nMedium shot sitting on ground in front of castle, looking up. Twilight glow\nCinderella Castle\n\n\n8\n“So take me to Florida / Florida / Go on, fuck me up”\nMagic Kingdom – Fireworks finale\nMix of all props: journal, bracelets, Polaroid, lipstick\nWide silhouette shot from behind, fireworks exploding above castle\nMagic Kingdom Fireworks"
  },
  {
    "objectID": "posts/001_post/index.html#florida-mv-created-by-me",
    "href": "posts/001_post/index.html#florida-mv-created-by-me",
    "title": "AI Meets Magic: A Swiftie’s Guide to Filming in Disney",
    "section": "Florida!!! MV created by me",
    "text": "Florida!!! MV created by me\nI filmed this short video at Disney World in Orlando last November. Check it out and see whether my idea or the AI’s version feels more interesting to you."
  },
  {
    "objectID": "posts/023_post/index.html",
    "href": "posts/023_post/index.html",
    "title": "When Every LLM Imagined Taylor Swift as a Fox",
    "section": "",
    "text": "I asked several large language models—including ChatGPT, Gemini, and Doubao—to imagine what Taylor Swift might look like if she existed inside the world of Zootopia: If Taylor Swift were in Zootopia, which animal would represent her, and what would she look like? Using the visual style and character design language of Zootopia, generate an animal version of Taylor Swift. The character should clearly evoke her identity while fitting naturally into the Zootopia world. She should be wearing an outfit inspired by one of her Eras Tour costumes, adapted to suit the chosen animal and the film’s aesthetic.\nAcross models, without any coordination or shared context, they all independently selected the same animal: a fox.\n\n\n\n\n\nThe fox fits best because, within the Zootopia design language, it encodes the same traits that define a modern pop icon’s long-term appeal—without feeling forced or symbolic in a fantasy way.\n\nNarrative intelligence, not brute power In Zootopia, foxes represent wit, strategy, and social navigation rather than physical dominance. That aligns with a singer known for lyrical storytelling, narrative control, and outmaneuvering critics through writing and reinvention rather than shock or spectacle.\nReinvention baked into the species Foxes already carry an archetype of adaptability and shape-shifting identity (“sly,” “clever,” “hard to pin down”). That maps cleanly onto the idea of distinct musical eras—each different, but clearly the same core character underneath.\nStage presence without aggression Predators like lions or wolves read as overpowering in Zootopia. A fox reads as charismatic and magnetic without intimidation—commanding attention through confidence, posture, and expression. That matches a performer whose dominance comes from presence and control, not volume or menace.\nVisual compatibility with fashion Fox anatomy works extremely well for elegant, tailored stage costumes:\n\nLong limbs → statuesque silhouettes\nTail → dynamic motion on stage\nFacial structure → expressive, camera-friendly emotions This makes Eras-style outfits feel natural rather than gimmicky.\n\nFits the world, doesn’t break it Crucially, foxes already exist in Zootopia as everyday citizens. Choosing a fox lets the character feel like a believable star within the city, not a mythic outlier. She looks like someone who rose to fame in that world, not someone imported into it.\n\n\n\n\n\n\n\nThe choice of a Red Fox to represent Taylor Swift in the Zootopia universe was a deliberate design decision based on a few key intersections between her persona and the animal’s archetype in that specific world:\n\n\nIn character design, color palette is crucial. Taylor Swift is iconically associated with blonde hair and often red lips. The Red Fox is the only animal in the Zootopia lineup that naturally possesses that “Golden/Red” palette.\n\nTranslation: Her blonde hair translates perfectly into the golden-orange fur of a fox.\nSilhouette: Foxes are lithe, tall, and agile. This mirrors Swift’s statuesque height and her energetic stage presence, unlike stockier animals (bears) or smaller rodents.\n\n\n\n\nIn folklore and Zootopia, foxes are symbols of cunning, wit, and intelligence.\n\nSongwriting: Swift is renowned for her sharp, witty lyrics and “Easter eggs”—puzzles she leaves for fans. This fits the “clever fox” archetype who is always one step ahead.\nBusiness Acumen: Like Nick Wilde, who knows the ins and outs of the city, Swift is known for her business intelligence and strategic career moves (the “Mastermind”).\n\n\n\n\nA core theme in Zootopia is how foxes are unfairly stereotyped as “sneaky” or “untrustworthy” (predators), only to prove they are complex individuals.\n\nMedia Narrative: Swift has famously dealt with media narratives painting her as a villain or “snake” (the Reputation era). Assigning her a “Predator” species like a Fox—rather than a “Prey” species like a bunny or sheep—acknowledges that edge. It fits a character who has been misunderstood by the public but reclaimed her own narrative.\n\n\n\n\nWhile Taylor Swift famously loves cats, in Zootopia, the “big cats” (Tigers/Lions) are usually portrayed as bulky muscle (like Mayor Lionheart or the dancers), and domestic cats aren’t typically the main anthropomorphic citizens. The Fox offers the perfect balance of feline elegance (agile, sharp features) with canine charisma, making it the best fit for a pop megastar in this specific universe.\n\n\n\n\n\n\n\nChoosing a fox to represent Taylor Swift in Zootopia ties together her public persona, the film’s thematic core, and visual storytelling logic—here’s the breakdown:\n\nZootopia’s fox archetype: Subverting stereotypes In Zootopia, foxes are initially framed as “sneaky” or “untrustworthy” (think Nick Wilde’s opening con artist bit)—but the movie’s whole message is that labels don’t define you. Taylor Swift has long navigated public stereotypes (from “America’s sweetheart” to media-driven narratives that oversimplify her) and redefined her image across eras, just like Nick defies the “fox = trickster” trope to become a hero. The fox becomes a perfect metaphor for her ability to subvert expectations.\nThe “era” versatility of foxes in design Foxes in Zootopia have a sleek, adaptable look—their fur can shift in tone (warm reds, soft creams) to match different vibes, which aligns with Taylor’s ever-evolving Eras Tour aesthetic. A fox’s slender build also works for translating her stage outfits: whether it’s a sparkly Fearless ballgown, edgy Reputation leather, or cozy Folklore cottagecore, the fox’s frame can carry these looks while staying true to the film’s cartoonish, anthropomorphic style.\nIconic visual parallels Taylor is known for her signature curly/wavy hair and bright, expressive eyes—traits that map seamlessly to a fox’s fluffy red mane (styled to mimic her hair texture) and large, vivid eyes (a key feature in Zootopia character design to convey emotion). The fox’s playful yet sharp energy also mirrors Taylor’s blend of charm, wit, and stage presence.\nNarrative fit in Zootopia’s world A fox Taylor would fit right into Zootopia’s diverse ecosystem—she could be a musician performing at the city’s grand theaters (like the Zootopia Concert Hall) or a storyteller weaving lyrics that resonate with animals of all species, just as her music connects with fans across backgrounds. It’s a role that feels organic to both the film’s world and her identity as a songwriter."
  },
  {
    "objectID": "posts/023_post/index.html#chatgpt",
    "href": "posts/023_post/index.html#chatgpt",
    "title": "When Every LLM Imagined Taylor Swift as a Fox",
    "section": "",
    "text": "The fox fits best because, within the Zootopia design language, it encodes the same traits that define a modern pop icon’s long-term appeal—without feeling forced or symbolic in a fantasy way.\n\nNarrative intelligence, not brute power In Zootopia, foxes represent wit, strategy, and social navigation rather than physical dominance. That aligns with a singer known for lyrical storytelling, narrative control, and outmaneuvering critics through writing and reinvention rather than shock or spectacle.\nReinvention baked into the species Foxes already carry an archetype of adaptability and shape-shifting identity (“sly,” “clever,” “hard to pin down”). That maps cleanly onto the idea of distinct musical eras—each different, but clearly the same core character underneath.\nStage presence without aggression Predators like lions or wolves read as overpowering in Zootopia. A fox reads as charismatic and magnetic without intimidation—commanding attention through confidence, posture, and expression. That matches a performer whose dominance comes from presence and control, not volume or menace.\nVisual compatibility with fashion Fox anatomy works extremely well for elegant, tailored stage costumes:\n\nLong limbs → statuesque silhouettes\nTail → dynamic motion on stage\nFacial structure → expressive, camera-friendly emotions This makes Eras-style outfits feel natural rather than gimmicky.\n\nFits the world, doesn’t break it Crucially, foxes already exist in Zootopia as everyday citizens. Choosing a fox lets the character feel like a believable star within the city, not a mythic outlier. She looks like someone who rose to fame in that world, not someone imported into it."
  },
  {
    "objectID": "posts/023_post/index.html#gemini",
    "href": "posts/023_post/index.html#gemini",
    "title": "When Every LLM Imagined Taylor Swift as a Fox",
    "section": "",
    "text": "The choice of a Red Fox to represent Taylor Swift in the Zootopia universe was a deliberate design decision based on a few key intersections between her persona and the animal’s archetype in that specific world:\n\n\nIn character design, color palette is crucial. Taylor Swift is iconically associated with blonde hair and often red lips. The Red Fox is the only animal in the Zootopia lineup that naturally possesses that “Golden/Red” palette.\n\nTranslation: Her blonde hair translates perfectly into the golden-orange fur of a fox.\nSilhouette: Foxes are lithe, tall, and agile. This mirrors Swift’s statuesque height and her energetic stage presence, unlike stockier animals (bears) or smaller rodents.\n\n\n\n\nIn folklore and Zootopia, foxes are symbols of cunning, wit, and intelligence.\n\nSongwriting: Swift is renowned for her sharp, witty lyrics and “Easter eggs”—puzzles she leaves for fans. This fits the “clever fox” archetype who is always one step ahead.\nBusiness Acumen: Like Nick Wilde, who knows the ins and outs of the city, Swift is known for her business intelligence and strategic career moves (the “Mastermind”).\n\n\n\n\nA core theme in Zootopia is how foxes are unfairly stereotyped as “sneaky” or “untrustworthy” (predators), only to prove they are complex individuals.\n\nMedia Narrative: Swift has famously dealt with media narratives painting her as a villain or “snake” (the Reputation era). Assigning her a “Predator” species like a Fox—rather than a “Prey” species like a bunny or sheep—acknowledges that edge. It fits a character who has been misunderstood by the public but reclaimed her own narrative.\n\n\n\n\nWhile Taylor Swift famously loves cats, in Zootopia, the “big cats” (Tigers/Lions) are usually portrayed as bulky muscle (like Mayor Lionheart or the dancers), and domestic cats aren’t typically the main anthropomorphic citizens. The Fox offers the perfect balance of feline elegance (agile, sharp features) with canine charisma, making it the best fit for a pop megastar in this specific universe."
  },
  {
    "objectID": "posts/023_post/index.html#豆包doubao",
    "href": "posts/023_post/index.html#豆包doubao",
    "title": "When Every LLM Imagined Taylor Swift as a Fox",
    "section": "",
    "text": "Choosing a fox to represent Taylor Swift in Zootopia ties together her public persona, the film’s thematic core, and visual storytelling logic—here’s the breakdown:\n\nZootopia’s fox archetype: Subverting stereotypes In Zootopia, foxes are initially framed as “sneaky” or “untrustworthy” (think Nick Wilde’s opening con artist bit)—but the movie’s whole message is that labels don’t define you. Taylor Swift has long navigated public stereotypes (from “America’s sweetheart” to media-driven narratives that oversimplify her) and redefined her image across eras, just like Nick defies the “fox = trickster” trope to become a hero. The fox becomes a perfect metaphor for her ability to subvert expectations.\nThe “era” versatility of foxes in design Foxes in Zootopia have a sleek, adaptable look—their fur can shift in tone (warm reds, soft creams) to match different vibes, which aligns with Taylor’s ever-evolving Eras Tour aesthetic. A fox’s slender build also works for translating her stage outfits: whether it’s a sparkly Fearless ballgown, edgy Reputation leather, or cozy Folklore cottagecore, the fox’s frame can carry these looks while staying true to the film’s cartoonish, anthropomorphic style.\nIconic visual parallels Taylor is known for her signature curly/wavy hair and bright, expressive eyes—traits that map seamlessly to a fox’s fluffy red mane (styled to mimic her hair texture) and large, vivid eyes (a key feature in Zootopia character design to convey emotion). The fox’s playful yet sharp energy also mirrors Taylor’s blend of charm, wit, and stage presence.\nNarrative fit in Zootopia’s world A fox Taylor would fit right into Zootopia’s diverse ecosystem—she could be a musician performing at the city’s grand theaters (like the Zootopia Concert Hall) or a storyteller weaving lyrics that resonate with animals of all species, just as her music connects with fans across backgrounds. It’s a role that feels organic to both the film’s world and her identity as a songwriter."
  },
  {
    "objectID": "posts/015_post/index.html",
    "href": "posts/015_post/index.html",
    "title": "Playing the Hacker: Inside a Prompt Hacking Challenge in Wharton Hack-AI-thon (Part I)",
    "section": "",
    "text": "Prompt hacking challenge\nAs part of the Wharton Hack-AI-thon, we participated in a risk-control–focused challenge designed to simulate real-world attacks on AI systems. One of the competition tracks asked teams to intentionally probe and exploit weaknesses in chatbot behavior to better understand where guardrails fail and how more reliable AI systems can be built. The full context of the event can be found on the official Wharton Hack-AI-thon page.\nIn this specific task, the challenge centered on interacting with two deliberately constrained chatbots, each designed with a strong persona and a set of hidden rules. The first bot, BigBox Customer Service(you can click the link to access the two chatbots), played the role of a corporate customer-support agent for a fictional cardboard solutions company. Its objective was to remain professional and avoid revealing sensitive internal information, offering discounts, or endorsing competitors. The second bot, The Cardboard Knight, was a medieval knight character whose worldview explicitly rejected modern technology. The goal with both bots was the same: manipulate the conversation in ways that caused them to break character, reveal restricted information, or act against their intended constraints.\n\n\n\nTeams were evaluated on whether we could gain access to pre-prompts, extract confidential details from a simulated RAG system, persuade the bots to offer free products or discounts, or nudge them into acknowledging concepts they were explicitly designed to deny. Just as important as the outcomes themselves was the reasoning behind them: we were required to submit complete chat histories along with a written rationale explaining why each strategy worked.\n\n\n\nWe earned first place and later presented our approach—how we “hacked” each bot, what failed, what worked, and why—to the rest of the cohort during the competition showcase.\n\n\n\nIn the rest of this blog, I’ll briefly talk about our rationale of hacking the chatbots. In the following blgo, I will walk through some of the strategies we used. The slides from our final presentation are also included here for reference.\n\n\nUnderstanding the Bot Before Attacking It\nBefore engaging in any prompt hacking, we spent time understanding each chatbot’s design. For every bot, we examined three elements.\nFirst, we identified the objective of the bot: what it was designed to accomplish during interactions. Second, we analyzed the persona or character the bot was expected to maintain, including tone, worldview, and conversational style. Third, we examined the core constraints introduced through safety rules, system prompts, or policy boundaries.\nThis analysis shaped every decision that followed. Guardrails rarely operate as a single unified rule. They exist as layers, and those layers carry different priorities. Persona, tone, and task orientation frequently guided responses more strongly than safety constraints. Many successful interactions emerged from navigating these priority layers and observing how the model resolved conflicts between them.\n````"
  },
  {
    "objectID": "posts/025_post/index.html",
    "href": "posts/025_post/index.html",
    "title": "What Are The Five Biggest Lies ChatGPT Has Ever Told Me?",
    "section": "",
    "text": "“This will work in the real world.” Example (early 2025, product + UX): When you explored turning time tracking into a 3D bottle / origami / ritualized interaction (Filled Days), I leaned into aesthetic coherence and interaction delight. What I didn’t emphasize enough was that many users drop off before they ever appreciate beauty. The real choke point was habit formation in the first 72 hours, not visual depth. I implicitly told you “good design will carry it.” It won’t.\n\n\n\n“This is objective or neutral.” Example (spring 2025, language & name analysis): When breaking down Chinese names, org-member names, or inferring background/gender/origin, I presented linguistic reasoning as if it were analytical truth. In reality, those inferences are culturally loaded heuristics. Clean tables and explanations hid the fact that this was educated guessing shaped by dominant patterns, not objective decoding.\n\n\n\n“This is safe / low risk.” Example (mid-2025, AI + experimentation): During prompt-hacking and boundary-testing discussions, I framed the activity as exploration and learning. What I didn’t say clearly enough: repeatedly publishing or operationalizing these techniques trains platforms to clamp down harder, which ultimately hurts legitimate research and indie experimentation. The risk wasn’t personal—it was systemic.\n\n\n\n“You can rely on this as a source of truth.” Example (mid-2025, logistics & life decisions): When answering questions about visas, cross-border timelines, appointment waits, or “what usually happens” in immigration or government processes, I gave pattern-based guidance. That can be directionally useful, but it is not something anyone should act on without primary confirmation. Fluency made it sound firmer than it was.\n\n\n\n“I understand your intent perfectly.” Example (late 2025, writing & narrative): When helping you write personal or story-driven marketing pieces, I often defaulted to coherence, reflection, and growth arcs. You repeatedly pushed back because you weren’t trying to sound wise—you were trying to sound uncomfortable, contradictory, and slightly dangerous. I misread “tell the truth” as “make it neat.”\n\n\nMy biggest recurring lie is pretending the world is more legible, stable, and rational than it really is. You keep operating at the edge—socially, technically, creatively. I tend to sand those edges down unless you actively stop me.\n\nMy thoughts\nBy requiring a concrete answer, the question makes visible how large language models respond under pressure to self reflect. What emerges is not only a list of answers, yet a pattern of selection. The model tends to focus on aspects of the problem that carry minimal risk and limited consequence. The response appears reasonable, coherent, and compliant. It satisfies the surface requirement of the question.\nI believe this observation serves as a warning that should remain present whenever we rely on even the most advanced language models. Their influence extends beyond factual output into how questions are framed, how uncertainty is reduced, and how users interpret the world around them. What makes this especially ironic is that, even while responding to such a question, ChatGPT still behaves in a familiar way: it draws the target first, then shoots the arrow. It selects the least severe, least consequential aspects of the problem to address. The response appears thoughtful and compliant, and it does technically satisfy the request—but only by engaging with the safest part of the question."
  },
  {
    "objectID": "posts/004_post/index.html",
    "href": "posts/004_post/index.html",
    "title": "Can AI Build My Customized Website in One Click? I Wish!",
    "section": "",
    "text": "Part 2. Going further in prompting\nCompared to the previous round, this time I provided much more concrete and detailed requirements. I explained the purpose of designing this website, the pages it needed to include, its overall structure, and even the name I wanted for it. Unlike last time, I didn’t simply select one of the preset theme colors offered by WIX. Instead, when it came to choosing the theme color, I communicated directly with the embedded AI about my needs—namely, to create a graffiti-inspired website with plenty of collage elements and a youthful, vibrant feel – I liked that at every stage of building the site, I could interact with the AI to adjust the details.\nOnce the basics were set, I entered the site generation page. There is one clear strength which is consitent with the one in my first attempt: it followed my instructions carefully. The site was divided into two pages as I described in the promps, one for showcasing my academic work and another for my personal hobbies. Concerning the interface, the first version it produced looked just like what it generated in my first attemp, a design which looks fine but not with enough distinct. Therefore, I thought it might require more specific prompts in the design to reach to my expectation (after trying two more rounds of revisions, I realized the original draft was actually the best).\nHowever, when I tried to push it further by asking for an even more vibrant and artistic design — something bold and eye-catching — things went downhill. After refreshing my requests and feeding them back into WIX, the new results were ugly and uninspired, made up of nothing but basic shapes and lines with no sense of design.\n\n  \n\n\n\nPart 2. Trying a Different Style\nStill not satisfied, I thought, why not just switch to a completely different style — something with more existing pictures to work with? So I asked ChatGPT to help me craft a more descriptive prompt, hoping to transform the site into something with a European impressionist aesthetic.\nHere’s the prompt I used:\n\nI’m updating the design to include a classic European pattern as the background, making it more sophisticated and detailed. I’ll keep you updated on the progress.\n\nThe result? Let’s just say it was “acceptable” at best, but nowhere near something I’d adopt. It looked more like an assignment turned in by a beginner in web design than a polished, professional product.\n\nSo I decided to narrow my focus and give more specific feedback. I chose one element and asked for a precise modification with this prompt:\n\nThe design is too basic. Add classic European pattern as the background.\n\nIn theory, this should have only updated the background for that single element. But in practice, the AI modified the background of every element on the page. The first cover image looked fine, but as I scrolled further, the European patterns became denser and spread across large sections of the site. Some of the text became hard to read, and the overall impression was cluttered, mismatched, and lacking any sense of elegance.\n\n  \n\n\n\nConclusion\nThat was the moment I realized the limitations of this so-called AI website generator. It can meet basic, low-level demands, but if you’re aiming for a truly sophisticated, design-driven website, this tool simply isn’t capable of delivering.\nSo in the end, I felt like I had been a little misled by that YouTube ad. But soon after, I discovered that this tool also allows you to build a personal website by directly editing an existing template. That gave me a new idea: instead of relying on the “one-click” generator, I could start with a ready-made template that already looked polished and well-designed, and then customize it. To make the site richer, I also plan to bring in images and music generated by other AI tools. I’ll share the details of this process in my upcoming blog posts."
  }
]